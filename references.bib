
@inproceedings{agarwalModelBasedReinforcementLearning2020,
  title = {Model-{{Based Reinforcement Learning}} with a {{Generative Model}} Is {{Minimax Optimal}}},
  booktitle = {Proceedings of {{Thirty Third Conference}} on {{Learning Theory}}},
  author = {Agarwal, Alekh and Kakade, Sham and Yang, Lin F.},
  date = {2020-07-15},
  pages = {67--83},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v125/agarwal20b.html},
  urldate = {2022-04-20},
  abstract = {This work considers the sample and computational complexity of obtaining an ϵϵ\textbackslash epsilon-optimal policy in a discounted Markov Decision Process (MDP), given only access to a generative model. In this model, the learner accesses the underlying transition model via a sampling oracle that provides a sample of the next state, when given any state-action pair as input. We are interested in a basic and unresolved question in model based planning: is this naïve “plug-in” approach — where we build the maximum likelihood estimate of the transition model in the MDP from observations and then find an optimal policy in this empirical MDP — non-asymptotically, minimax optimal? Our main result answers this question positively. With regards to computation, our result provides a simpler approach towards minimax optimal planning: in comparison to prior model-free results,  we show that using \textbackslash emph\{any\} high accuracy, black-box planning oracle in the empirical model suffices to obtain the minimax error rate. The key proof technique uses a leave-one-out analysis, in a novel “absorbing MDP” construction, to decouple the statistical dependency issues that arise in the analysis of model-based planning; this construction may be helpful more generally.},
  eventtitle = {Conference on {{Learning Theory}}},
  langid = {english}
}

@article{ahvanooeySurveyGeneticProgramming2019,
  title = {A {{Survey}} of {{Genetic Programming}} and {{Its Applications}}},
  author = {Ahvanooey, Milad Taleby and Li, Qianmu and Wu, Ming and Wang, Shuo},
  date = {2019},
  journaltitle = {KSII Transactions on Internet and Information Systems (TIIS)},
  volume = {13},
  number = {4},
  pages = {1765--1794},
  publisher = {{Korean Society for Internet Information}},
  issn = {1976-7277},
  doi = {10.3837/tiis.2019.04.002},
  url = {https://www.koreascience.or.kr/article/JAKO201919761177651.page},
  urldate = {2022-04-20},
  abstract = {Genetic Programming (GP) is an intelligence technique whereby computer programs are encoded as a set of genes which are evolved utilizing a Genetic Algorithm (GA). In other words, the GP employs novel optimization techniques to modify computer programs; imitating the way humans develop programs by progressively re-writing them for solving problems automatically. Trial programs are frequently altered in the search for obtaining superior solutions due to the base is GA. These are evolutionary search techniques inspired by biological evolution such as mutation, reproduction, natural selection, recombination, and survival of the fittest. The power of GAs is being represented by an advancing range of applications; vector processing, quantum computing, VLSI circuit layout, and so on. But one of the most significant uses of GAs is the automatic generation of programs. Technically, the GP solves problems automatically without having to tell the computer specifically how to process it. To meet this requirement, the GP utilizes GAs to a "population" of trial programs, traditionally encoded in memory as tree-structures. Trial programs are estimated using a "fitness function" and the suited solutions picked for re-evaluation and modification such that this sequence is replicated until a "correct" program is generated. GP has represented its power by modifying a simple program for categorizing news stories, executing optical character recognition, medical signal filters, and for target identification, etc. This paper reviews existing literature regarding the GPs and their applications in different scientific fields and aims to provide an easy understanding of various types of GPs for beginners.},
  langid = {english}
}

@article{arslanMultiHiveArtificial2019,
  title = {Multi {{Hive Artificial Bee Colony Programming}} for High Dimensional Symbolic Regression with Feature Selection},
  author = {Arslan, Sibel and Ozturk, Celal},
  date = {2019-05-01},
  journaltitle = {Applied Soft Computing},
  volume = {78},
  pages = {515--527},
  doi = {10.1016/j.asoc.2019.03.014},
  abstract = {Abstract   Feature selection is a process that provides model extraction by specifying necessary or related features and improves generalization. The Artificial Bee Colony (ABC) algorithm is one of the most popular optimization algorithms inspired on swarm intelligence developed by simulating the search behavior of honey bees. Artificial Bee Colony Programming (ABCP) is a recently proposed high level automatic programming technique for a Symbolic Regression (SR) problem based on the ABC algorithm. In this paper, a new feature selection method based on ABCP is proposed, Multi Hive ABCP (MHABCP) for high-dimensional SR problems. The learning ability and generalization performance of the proposed MHABCP is investigated using synthetic and real high-dimensional SR datasets and is compared with basic ABCP and GP automatic programming methods. Experimental results show that MHABCP has better performance choosing relevant features in high dimensional SR problems and generalization than other methods.},
  annotation = {MAG ID: 2922470279}
}

@article{astarabadiAvoidingOverfittingSymbolic2015,
  title = {Avoiding {{Overfitting}} in {{Symbolic Regression Using}} the {{First Order Derivative}} of {{GP Trees}}},
  author = {Astarabadi, Samaneh Sadat Mousavi and Ebadzadeh, Mohammad Mehdi},
  date = {2015-07-11},
  pages = {1441--1442},
  doi = {10.1145/2739482.2764662},
  abstract = {Genetic programming (GP) is widely used for constructing models with applications in control, classification, regression, etc.; however, it has some shortcomings, such as generalization. This paper proposes to enhance the GP generalization by controlling the first order derivative of GP trees in the evolution process. To achieve this goal, a multi-objective GP is implemented. Then, the first order derivative of GP trees is considered as one of its objectives. The proposed method is evaluated on several benchmark problems to provide an experimental validation. The experiments demonstrate the usefulness of the proposed method with the capability of achieving compact solutions with reasonable accuracy on training data and better accuracy on test data.},
  annotation = {MAG ID: 2029700197}
}

@incollection{banzhafGeneticProgrammingIntroduction1998a,
  title = {Genetic {{Programming}}: {{An Introduction}} on the {{Automatic Evolution}} of Computer Programs and Its {{Applications}}},
  shorttitle = {Genetic {{Programming}}},
  author = {Banzhaf, Wolfgang and Nordin, Peter and Keller, Robert and Francone, Frank},
  date = {1998-01-01}
}

@article{cramerRepresentationAdaptiveGeneration1985,
  title = {A Representation for the {{Adaptive Generation}} of {{Simple Sequential Programs}}},
  author = {Cramer, Nichael Lynn},
  date = {1985},
  doi = {10.5555/645511.657085},
  url = {http://www.cs.ucl.ac.uk/staff/W.Langdon/ftp/papers/icga1985/icga85_cramer.pdf},
  abstract = {An adaptive system for generating short sequential computer functions is described. The created functions are written in the simple \{"\}number-string\{"\} language JB, and in TB, a modified version of JB with a tree-like structure. These languages have the feature that they can be used to represent well-formed, useful computer programs while still being amenable to suitably defined genetic operators. The system is used to produce two-input, single-output multiplication functions that are concise and well-defined. Future work, dealing with extensions to more complicated functions and generalizations of the techniques, is also discussed.},
  issue = {Proceedings of an International Conference on Genetic Algorithms and the Applications}
}

@online{deapprojectArtificialAntProblem,
  title = {Artificial {{Ant Problem}} — {{DEAP}} 1.3.1 Documentation},
  author = {{DEAP Project}},
  url = {https://deap.readthedocs.io/en/master/examples/gp_ant.html},
  urldate = {2022-04-27}
}

@inproceedings{defreitasEvolvingControllersMario2018,
  title = {Evolving {{Controllers}} for {{Mario AI Using Grammar-based Genetic Programming}}},
  booktitle = {2018 {{IEEE Congress}} on {{Evolutionary Computation}} ({{CEC}})},
  author = {de Freitas, João Marcos and de Souza, Felipe Rafael and Bernardino, Heder S.},
  options = {useprefix=true},
  date = {2018-07},
  pages = {1--8},
  doi = {10.1109/CEC.2018.8477698},
  abstract = {Video games mimic real-world situations and they can be used as a benchmark to evaluate computational methods in solving different types of problems. Also, machine learning methods are used nowadays to improve the quality of non-player characters in order (i) to create human like behaviors, and (ii) to increase the hardness of the games. Genetic Programming (GP) has presented good results when evolving programs in general. One of the main advantage of GP is the availability of the source-code of its solutions, helping researchers to understand the decision-making process. Also, a formal grammar can be used in order to facilitate the generation of programs in more complex languages (such as Java, C, and Python). Here, we propose the use of Grammar-based Genetic Programming (GGP) to evolve controllers for Mario AI, a popular platform to test video game controllers which simulates the Nintendo's Super Mario Bros. Also, as GP provides the source-code of the solutions, we present and analyze the best program obtained. Finally, GGP is compared to other techniques from the literature and the results show that GGP find good controllers, specially with respect to the scores obtained on higher difficulty levels.},
  eventtitle = {2018 {{IEEE Congress}} on {{Evolutionary Computation}} ({{CEC}})},
  keywords = {Artificial intelligence,Decision making,game controller,Games,Genetic programming,Grammar,grammar-based genetic programming,mario ai,Sociology,Statistics}
}

@online{dyerCS540Lecture,
  title = {{{CS}} 540 {{Lecture Notes}}: {{Game Playing}}},
  author = {Dyer, Charles R.},
  url = {https://pages.cs.wisc.edu/~dyer/cs540/notes/games.html},
  urldate = {2022-04-26}
}

@article{espejoSurveyApplicationGenetic2010,
  title = {A {{Survey}} on the {{Application}} of {{Genetic Programming}} to {{Classification}}},
  author = {Espejo, Pedro G. and Ventura, Sebastián and Herrera, Francisco},
  date = {2010-03},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume = {40},
  number = {2},
  pages = {121--144},
  issn = {1558-2442},
  doi = {10.1109/TSMCC.2009.2033566},
  abstract = {Classification is one of the most researched questions in machine learning and data mining. A wide range of real problems have been stated as classification problems, for example credit scoring, bankruptcy prediction, medical diagnosis, pattern recognition, text categorization, software quality assessment, and many more. The use of evolutionary algorithms for training classifiers has been studied in the past few decades. Genetic programming (GP) is a flexible and powerful evolutionary technique with some features that can be very valuable and suitable for the evolution of classifiers. This paper surveys existing literature about the application of genetic programming to classification, to show the different ways in which this evolutionary algorithm can help in the construction of accurate and reliable classifiers.},
  eventtitle = {{{IEEE Transactions}} on {{Systems}}, {{Man}}, and {{Cybernetics}}, {{Part C}} ({{Applications}} and {{Reviews}})},
  keywords = {Classification,Classification tree analysis,Computer science,Data mining,decision trees,Decision trees,ensemble classifiers,Evolutionary computation,feature construction,feature selection,Genetic programming,genetic programming (GP),Machine learning,Medical diagnosis,rule-based systems,Supervised learning,Unsupervised learning}
}

@inreference{EvaluationFunction2022,
  title = {Evaluation Function},
  booktitle = {Wikipedia},
  date = {2022-03-27T08:39:41Z},
  url = {https://en.wikipedia.org/w/index.php?title=Evaluation_function&oldid=1079533564},
  urldate = {2022-04-18},
  abstract = {An evaluation function, also known as a heuristic evaluation function or static evaluation function, is a function used by game-playing computer programs to estimate the value or goodness of a position (usually at a leaf or terminal node) in a game tree. Most of the time, the value is either a real number or a quantized integer, often in nths of the value of a playing piece such as a stone in go or a pawn in chess, where n may be tenths, hundredths or other convenient fraction, but sometimes, the value is an array of three values in the unit interval, representing the win, draw, and loss percentages of the position.  There do not exist analytical or theoretical models for evaluation functions for unsolved games, nor are such functions entirely ad-hoc.  The composition of evaluation functions is determined empirically by inserting a candidate function into an automaton and evaluating its subsequent performance.  A significant body of evidence now exists for several games like chess, shogi and go as to the general composition of evaluation functions for them. Games in which game playing computer programs employ evaluation functions include chess, go, shogi (Japanese chess), othello, hex, backgammon, and checkers. In addition, with the advent of programs such as MuZero, computer programs also use evaluation functions to play video games, such as those from the Atari 2600. Some games like tic-tac-toe are strongly solved, and do not require search or evaluation because a discrete solution tree is available.},
  langid = {english},
  annotation = {Page Version ID: 1079533564}
}

@article{fanMinimaxTheorems1953,
  title = {Minimax {{Theorems}}},
  author = {Fan, Ky},
  date = {1953-01},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {39},
  number = {1},
  eprint = {16589233},
  eprinttype = {pmid},
  pages = {42--47},
  issn = {0027-8424},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1063722/},
  urldate = {2022-04-18},
  pmcid = {PMC1063722}
}

@article{forsythBEAGLEDARWINIANAPPROACH1981,
  title = {{{{\emph{BEAGLE}}}} —{{A DARWINIAN APPROACH TO PATTERN RECOGNITION}}},
  author = {Forsyth, Richard},
  date = {1981-03-01},
  journaltitle = {Kybernetes},
  volume = {10},
  number = {3},
  pages = {159--166},
  issn = {0368-492X},
  doi = {10.1108/eb005587},
  url = {https://www.emerald.com/insight/content/doi/10.1108/eb005587/full/html},
  urldate = {2022-04-20},
  abstract = {BEAGLE (Biological Evolutionary Algorithm Generating Logical Expressions) is a computer package for producing decision‐rules by induction from a database. It works on the principle of “Naturalistic Selection” whereby rules that fit the data badly are “killed off” and replaced by “mutations” of better rules or by new rules created by “mating” two better adapted rules. The rules are Boolean expressions represented by tree structures. The software consists of two               Pascal               programs,               HERB               (Heuristic Evolutionary Rule Breeder) and               LEAF               (Logical Evaluator And Forecaster).               HERB               improves a given starting set of rules by running over several simulated generations.               LEAF               uses the rules to classify samples from a database where the correct membership may not be known. Preliminary tests on three different databases have been carried out—on hospital admissions (classing heart patients as deaths or survivors), on athletic physique (classing Olympic finalists as long‐distance runners or sprinters) and on football results (categorizing games into draws and non‐draws). It appears from the tests that the method works better than the standard discriminant analysis technique based on a linear discriminant function, and hence that this long‐neglected approach warrants further investigation.},
  langid = {english}
}

@software{fortinDeapAntPy2022,
  title = {Deap/Ant.Py at B8513fc16fa05b2fe6b740488114a7f0c5a1dd06 · {{DEAP}}/Deap},
  date = {2022-04-27T18:15:05Z},
  origdate = {2014-05-21T20:07:39Z},
  url = {https://github.com/DEAP/deap/blob/b8513fc16fa05b2fe6b740488114a7f0c5a1dd06/examples/gp/ant.py},
  urldate = {2022-04-27},
  abstract = {Distributed Evolutionary Algorithms in Python},
  editora = {Fortin, Félix-Antoine and Elliston, Ben},
  editoratype = {collaborator},
  organization = {{Distributed Evolutionary Algorithms in Python}}
}

@inreference{GeneticProgramming2022,
  title = {Genetic Programming},
  booktitle = {Wikipedia},
  date = {2022-04-16T21:17:12Z},
  url = {https://en.wikipedia.org/w/index.php?title=Genetic_programming&oldid=1083071637},
  urldate = {2022-04-20},
  abstract = {In artificial intelligence, genetic programming (GP) is a technique of evolving programs, starting from a population of unfit (usually random) programs, fit for a particular task by applying operations analogous to natural genetic processes to the population of programs. The operations are: selection of the fittest programs for reproduction (crossover) and mutation according to a predefined fitness measure, usually proficiency at the desired task.  The crossover operation involves swapping random parts of selected pairs (parents) to produce new and different offspring that become part of the new generation of programs.  Mutation involves substitution of some random part of a program with some other random part of a program. Some programs not selected for reproduction are copied from the current generation to the new generation. Then the selection and other operations are recursively applied to the new generation of programs. Typically, members of each new generation are on average more fit than the members of the previous generation, and the best-of-generation program is often better than the best-of-generation programs from previous generations.  Termination of the evolution usually occurs when some individual program reaches a predefined proficiency or fitness level. It may and often does happen that a particular run of the algorithm results in premature convergence to some local maximum which is not a globally optimal or even good solution.  Multiple runs (dozens to hundreds) are usually necessary to produce a very good result.  It may also be necessary to increase the starting population size and variability of the individuals to avoid pathologies.},
  langid = {english},
  annotation = {Page Version ID: 1083071637}
}

@article{haeriImprovingGPGeneralization2015,
  title = {Improving {{GP}} Generalization: A Variance-Based Layered Learning Approach},
  author = {Haeri, Maryam Amir and Ebadzadeh, Mohammad Mehdi and Folino, Gianluigi},
  date = {2015-03-01},
  journaltitle = {Genetic Programming and Evolvable Machines},
  volume = {16},
  number = {1},
  pages = {27--55},
  doi = {10.1007/s10710-014-9220-6},
  abstract = {This paper introduces a new method that improves the generalization ability of genetic programming (GP) for symbolic regression problems, named variance-based layered learning GP. In this approach, several datasets, called primitive training sets, are derived from the original training data. They are generated from less complex to more complex, for a suitable complexity measure. The last primitive dataset is still less complex than the original training set. The approach decomposes the evolution process into several hierarchical layers. The first layer of the evolution starts using the least complex (smoothest) primitive training set. In the next layers, more complex primitive sets are given to the GP engine. Finally, the original training data is given to the algorithm. We use the variance of the output values of a function as a measure of the functional complexity. This measure is utilized in order to generate smoother training data, and controlling the functional complexity of the solutions to reduce the overfitting. The experiments, conducted on four real-world and three artificial symbolic regression problems, demonstrate that the approach enhances the generalization ability of the GP, and reduces the complexity of the obtained solutions.},
  annotation = {MAG ID: 2074097796}
}

@book{hollandAdaptationNaturalArtificial2019,
  title = {Adaptation in {{Natural}} and {{Artificial Systems}} - {{An Introductory Analysis}} with {{Applications}} to {{Biology}}, {{Control}}, and {{Artificial I}}},
  author = {Holland, John H},
  date = {2019},
  url = {http://www.vlebooks.com/vleweb/product/openreader?id=none&isbn=9780262275552},
  urldate = {2022-04-26},
  isbn = {978-0-262-27555-2},
  langid = {english},
  annotation = {OCLC: 1235962848}
}

@article{jeffersonGenesysSystemEvolution1990,
  title = {The {{Genesys System}}: {{Evolution}} as a {{Theme}} in {{Artificial Life}}},
  shorttitle = {The {{Genesys System}}},
  author = {Jefferson, David and Collins, Rob},
  date = {1990-01-01},
  journaltitle = {Artificial Life - ALIFE},
  shortjournal = {Artificial Life - ALIFE}
}

@article{kellyScalingGeneticProgramming2018,
  title = {Scaling {{Genetic Programming}} to {{Challenging Reinforcement Tasks}} through {{Emergent Modularity}}},
  author = {Kelly, Stephen},
  date = {2018-06-21T16:04:28Z},
  url = {https://DalSpace.library.dal.ca//handle/10222/73979},
  urldate = {2022-04-20},
  abstract = {Algorithms that learn through environmental interaction and delayed rewards, or reinforcement learning, increasingly face the challenge of scaling to dynamic, high-dimensional environments. Video games model these types of real-world decision-making and control scenarios while being simple enough to implement within experiments. This work demonstrates how emergent modularity and open-ended evolution allow genetic programming (GP) to discover strategies for difficult gaming scenarios while maintaining relatively low model complexity. Two related learning algorithms are considered: Policy Trees and Tangled Program Graphs (TPG).     In the case of Policy Trees, a methodology for transfer learning is proposed which specifically leverages both structural and behavioural modularity in the learner representation. The utility of the approach is empirically evaluated in two challenging task domains: RoboCup Soccer and Ms. Pac-Man. In RoboCup, decision-making policies are first evolved for simple subtasks and then reused within a policy hierarchy in order to learn the more complex task of Half-Field Offense. The same methodology is applied to Ms. Pac-Man, in which case the use of task-agnostic diversity maintenance enables the automatic discovery of suitable sub-policies, removing the need for a prior human-specified task decomposition. In both task domains, the final GP decision-making policies reach state-of-the-art levels of play while being significantly less complex than solutions from temporal difference methods and neuroevolution.       TPG takes a more open-ended approach to modularity, emphasizing the ability to adaptively complexify policies through interaction with the task environment. The challenging Atari video game environment is used to show that this approach builds decision-making policies that broadly match the quality of several deep learning methods while being several orders of magnitude less computationally demanding, both in terms of sample efficiency and model complexity. Finally, the approach is capable of evolving solutions to multiple game titles simultaneously with no additional computational cost. In this case, agent behaviours for an individual game as well as single agents capable of playing up to 5 games emerge from the same evolutionary run.},
  langid = {english},
  annotation = {Accepted: 2018-06-21T16:04:28Z}
}

@online{KotlinProgrammingLanguage,
  title = {Kotlin {{Programming Language}}},
  url = {https://kotlinlang.org/},
  urldate = {2022-05-27},
  langid = {english},
  organization = {{Kotlin}}
}

@incollection{kozaGeneticProgramming2005,
  title = {Genetic {{Programming}}},
  booktitle = {Search {{Methodologies}}: {{Introductory Tutorials}} in {{Optimization}} and {{Decision Support Techniques}}},
  author = {Koza, John R. and Poli, Riccardo},
  editor = {Burke, Edmund K. and Kendall, Graham},
  date = {2005},
  pages = {127--164},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/0-387-28356-0_5},
  url = {https://doi.org/10.1007/0-387-28356-0_5},
  urldate = {2022-04-20},
  abstract = {The goal of getting computers to automatically solve problems is central to artificial intelligence, machine learning, and the broad area encompassed by what Turing called “machine intelligence„ (Turing, 1948, 1950). In his talk entitled AI: Where It Has Been and Where It Is Going, machine learning pioneer Arthur Samuel stated the main goal of the fields of machine learning and artificial intelligence: [T]he aim [is]... to get machines to exhibit behavior, which if done by humans, would be assumed to involve the use of intelligence. (Samuel, 1983) Genetic programming is a systematic method for getting computers to automatically solve a problem starting from a high-level statement of what needs to be done. Genetic programming is a domain-independent method that genetically breeds a population of computer programs to solve a problem. Specifically, genetic programming iteratively transforms a population of computer programs into a new generation of programs by applying analogs of naturally occurring genetic operations. This process is illustrated in Figure 5.1.},
  isbn = {978-0-387-28356-2},
  langid = {english},
  keywords = {Crossover Point,Fitness Measure,Genetic Operation,Genetic Programming,Preparatory Step}
}

@article{kozaGeneticProgrammingMeans1994a,
  title = {Genetic Programming as a Means for Programming Computers by Natural Selection},
  author = {Koza, John R.},
  date = {1994-06-01},
  journaltitle = {Statistics and Computing},
  shortjournal = {Stat Comput},
  volume = {4},
  number = {2},
  pages = {87--112},
  issn = {1573-1375},
  doi = {10.1007/BF00175355},
  url = {https://doi.org/10.1007/BF00175355},
  urldate = {2022-04-22},
  abstract = {Many seemingly different problems in machine learning, artificial intelligence, and symbolic processing can be viewed as requiring the discovery of a computer program that produces some desired output for particular inputs. When viewed in this way, the process of solving these problems becomes equivalent to searching a space of possible computer programs for a highly fit individual computer program. The recently developed genetic programming paradigm described herein provides a way to search the space of possible computer programs for a highly fit individual computer program to solve (or approximately solve) a surprising variety of different problems from different fields. In genetic programming, populations of computer programs are genetically bred using the Darwinian principle of survival of the fittest and using a genetic crossover (sexual recombination) operator appropriate for genetically mating computer programs. Genetic programming is illustrated via an example of machine learning of the Boolean 11-multiplexer function and symbolic regression of the econometric exchange equation from noisy empirical data.},
  langid = {english},
  keywords = {Boolean 11-multiplexer,Boolean 11-parity,crossover,econometric exchange equation,genetic algorithm,Genetic programming,hierarchical automatic function definition,symbolic regression}
}

@patent{kozaNonlinearGeneticAlgorithms1990,
  type = {patentus},
  title = {Non-Linear Genetic Algorithms for Solving Problems},
  author = {Koza, John R.},
  holder = {{Koza John R}},
  date = {1990-06-19},
  number = {4935877A},
  url = {https://patents.google.com/patent/US4935877A/en},
  urldate = {2022-04-26},
  abstract = {The present invention is a non-linear genetic algorithm for problem solving. The iterative process of the present invention operates on a population of problem solving entities. First, the activated entities perform, producing results. Then the results are assigned values and associated with the producing entity. Next, entities having relatively high associated values are selected. The selected entities perform either crossover, reproduction, or permutation operations. Lastly, the newly created entities are added to the population.},
  keywords = {crossover,entity,population,program,value}
}

@inproceedings{kuscuEvolvingGeneralisedBehaviour1998,
  title = {Evolving a Generalised Behaviour: {{Artificial}} Ant Problem Revisited},
  shorttitle = {Evolving a Generalised Behaviour},
  booktitle = {Evolutionary {{Programming VII}}},
  author = {Kuscu, Ibrahim},
  editor = {Porto, V. W. and Saravanan, N. and Waagen, D. and Eiben, A. E.},
  date = {1998},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {799--808},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/BFb0040830},
  abstract = {This research aims to demonstrate that a solution for artificial ant problem [4] is very likely to be non-general and relying on the specific characteristics of the Santa Fe trail. It then presents a consistent method which promotes producing general solutions. Using the concepts of training and testing from machine learning research, the method can be useful in producing general behaviours for simulation environments.},
  isbn = {978-3-540-68515-9},
  langid = {english},
  keywords = {Fitness Case,Genetic Programming,Genetic Programming System,Machine Learning Research,Perfect Performance}
}

@article{kuscuPromotingGeneralisationLearned1998,
  title = {Promoting {{Generalisation}} of {{Learned Behaviours}} in {{Genetic Programming}}},
  author = {Kuscu, Ibrahim},
  date = {1998-09-27},
  pages = {491--500},
  doi = {10.1007/bfb0056891},
  abstract = {Recently, growing numbers of research concentrate on robustness of the programs evolved using Genetic Programming (GP). While some of the researchers report on the brittleness of the solutions evolved, some others proposed methods of promoting robustness. It is important that these methods are not ad hoc and specific for a certain experimental setup. In this research, brittleness of solutions found for the artificial ant problem is reported and a new method promoting generalisation of the solutions in GP is presented.},
  annotation = {MAG ID: 1598236549}
}

@book{langdonFoundationsGeneticProgramming2013,
  title = {Foundations of {{Genetic Programming}}},
  author = {Langdon, William B. and Poli, Riccardo},
  date = {2013-03-09},
  eprint = {zsaqCAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Springer Science \& Business Media}},
  abstract = {Genetic programming (GP), one of the most advanced forms of evolutionary computation, has been highly successful as a technique for getting computers to automatically solve problems without having to tell them explicitly how. Since its inceptions more than ten years ago, GP has been used to solve practical problems in a variety of application fields. Along with this ad-hoc engineering approaches interest increased in how and why GP works. This book provides a coherent consolidation of recent work on the theoretical foundations of GP. A concise introduction to GP and genetic algorithms (GA) is followed by a discussion of fitness landscapes and other theoretical approaches to natural and artificial evolution. Having surveyed early approaches to GP theory it presents new exact schema analysis, showing that it applies to GP as well as to the simpler GAs. New results on the potentially infinite number of possible programs are followed by two chapters applying these new techniques.},
  isbn = {978-3-662-04726-2},
  langid = {english},
  pagetotal = {265},
  keywords = {Computers / Artificial Intelligence / General,Computers / Computer Science,Computers / Data Science / General,Computers / Information Technology,Computers / Information Theory,Computers / Programming / Algorithms,Mathematics / Discrete Mathematics}
}

@inproceedings{linGradientDescentAscent2020,
  title = {On {{Gradient Descent Ascent}} for {{Nonconvex-Concave Minimax Problems}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Lin, Tianyi and Jin, Chi and Jordan, Michael},
  date = {2020-11-21},
  pages = {6083--6093},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/lin20a.html},
  urldate = {2022-04-20},
  abstract = {We consider nonconvex-concave minimax problems, minxmaxy∈Yf(x,y)minxmaxy∈Yf(x,y)\textbackslash min\_\{\textbackslash mathbf\{x\}\} \textbackslash max\_\{\textbackslash mathbf\{y\} \textbackslash in \textbackslash mathcal\{Y\}\} f(\textbackslash mathbf\{x\}, \textbackslash mathbf\{y\}), where fff is nonconvex in xx\textbackslash mathbf\{x\} but concave in yy\textbackslash mathbf\{y\} and YY\textbackslash mathcal\{Y\} is a convex and bounded set. One of the most popular algorithms for solving this problem is the celebrated gradient descent ascent (GDA) algorithm, which has been widely used in machine learning, control theory and economics. Despite the extensive convergence results for the convex-concave setting, GDA with equal stepsize can converge to limit cycles or even diverge in a general setting. In this paper, we present the complexity results on two-time-scale GDA for solving nonconvex-concave minimax problems, showing that the algorithm can find a stationary point of the function Φ(⋅):=maxy∈Yf(⋅,y)Φ(⋅):=maxy∈Yf(⋅,y)\textbackslash Phi(\textbackslash cdot) := \textbackslash max\_\{\textbackslash mathbf\{y\} \textbackslash in \textbackslash mathcal\{Y\}\} f(\textbackslash cdot, \textbackslash mathbf\{y\}) efficiently. To the best our knowledge, this is the first nonasymptotic analysis for two-time-scale GDA in this setting, shedding light on its superior practical performance in training generative adversarial networks (GANs) and other real applications.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{linNearOptimalAlgorithmsMinimax2020,
  title = {Near-{{Optimal Algorithms}} for {{Minimax Optimization}}},
  booktitle = {Proceedings of {{Thirty Third Conference}} on {{Learning Theory}}},
  author = {Lin, Tianyi and Jin, Chi and Jordan, Michael I.},
  date = {2020-07-15},
  pages = {2738--2779},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v125/lin20a.html},
  urldate = {2022-04-20},
  abstract = {This paper resolves a longstanding open question pertaining to the design of near-optimal first-order algorithms for smooth and strongly-convex-strongly-concave minimax problems. Current state-of-the-art first-order algorithms find an approximate Nash equilibrium using O\textasciitilde (κx+κy)O\textasciitilde (κx+κy)\textbackslash tilde\{O\}(\textbackslash kappa\_x+\textbackslash kappa\_y) or O\textasciitilde (min\{κxκy−−√,κx−−√κy\})O\textasciitilde (min\{κxκy,κxκy\})\textbackslash tilde\{O\}(\textbackslash text\{min\}\textbackslash\{\textbackslash kappa\_x\textbackslash sqrt\{\textbackslash kappa\_y\}, \textbackslash sqrt\{\textbackslash kappa\_x\}\textbackslash kappa\_y\textbackslash\})~ gradient evaluations, where κxκx\textbackslash kappa\_x and κyκy\textbackslash kappa\_y are the condition numbers for the strong-convexity and strong-concavity assumptions. A gap still remains between these results and the best existing lower bound Ω\textasciitilde (κxκy−−−−√)Ω\textasciitilde (κxκy)\textbackslash tilde\{\textbackslash Omega\}(\textbackslash sqrt\{\textbackslash kappa\_x\textbackslash kappa\_y\}).  This paper presents the first algorithm with O\textasciitilde (κxκy−−−−√)O\textasciitilde (κxκy)\textbackslash tilde\{O\}(\textbackslash sqrt\{\textbackslash kappa\_x\textbackslash kappa\_y\}) gradient complexity, matching the lower bound up to logarithmic factors. Our algorithm is designed based on an accelerated proximal point method and an accelerated solver for minimax proximal steps.  It can be easily extended to the settings of strongly-convex-concave, convex-concave, nonconvex-strongly-concave, and nonconvex-concave functions. This paper also presents algorithms that match or outperform all existing methods in these settings in terms of gradient complexity, up to logarithmic factors.},
  eventtitle = {Conference on {{Learning Theory}}},
  langid = {english}
}

@inproceedings{linUnsupervisedVideoGame2021,
  title = {An Unsupervised Video Game Playstyle Metric via State Discretization},
  booktitle = {Proceedings of the {{Thirty-Seventh Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  author = {Lin, Chiu-Chou and Chiu, Wei-Chen and Wu, I.-Chen},
  date = {2021-12-01},
  pages = {215--224},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v161/lin21a.html},
  urldate = {2022-04-20},
  abstract = {On playing video games, different players usually have their own playstyles. Recently, there have been great improvements for the video game AIs on the playing strength. However, past researches for analyzing the behaviors of players still used heuristic rules or the behavior features with the game-environment support, thus being exhausted for the developers to define the features of discriminating various playstyles. In this paper, we propose the first metric for video game playstyles directly from the game observations and actions, without any prior specification on the playstyle in the target game. Our proposed method is built upon a novel scheme of learning discrete representations that can map game observations into latent discrete states, such that playstyles can be exhibited from these discrete states. Namely, we measure the playstyle distance based on game observations aligned to the same states. We demonstrate high playstyle accuracy of our metric in experiments on some video game platforms, including TORCS, RGSK, and seven Atari games, and for different agents including rule-based AI bots, learning-based AI bots, and human players.},
  eventtitle = {Uncertainty in {{Artificial Intelligence}}},
  langid = {english}
}

@software{magarenacommunityMagarenaMagarena2022,
  title = {Magarena/Magarena},
  date = {2022-04-14T08:23:15Z},
  origdate = {2014-01-26T10:14:56Z},
  url = {https://github.com/magarena/magarena},
  urldate = {2022-04-18},
  abstract = {Magarena is a single-player fantasy card game played against a computer opponent.},
  editora = {{Magarena Community}},
  editoratype = {collaborator},
  organization = {{MagArena}},
  keywords = {card,game}
}

@book{maschlerGameTheory2013,
  title = {Game {{Theory}}},
  author = {Maschler, Michael and Solan, Eilon and Zamir, Shmuel},
  date = {2013},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  doi = {10.1017/CBO9780511794216},
  url = {http://ebooks.cambridge.org/ref/id/CBO9780511794216},
  urldate = {2022-04-18},
  isbn = {978-0-511-79421-6}
}

@inreference{Minimax2022,
  title = {Minimax},
  booktitle = {Wikipedia},
  date = {2022-03-12T19:58:33Z},
  url = {https://en.wikipedia.org/w/index.php?title=Minimax&oldid=1076761456},
  urldate = {2022-04-18},
  abstract = {Minimax (sometimes MinMax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for minimizing the possible loss for a worst case (maximum loss) scenario.  When dealing with gains, it is referred to as "maximin"—to maximize the minimum gain.  Originally formulated for n-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been extended to more complex games and to general decision-making in the presence of uncertainty.},
  langid = {english},
  annotation = {Page Version ID: 1076761456}
}

@article{nicolauChoosingFunctionSets2021,
  title = {Choosing Function Sets with Better Generalisation Performance for Symbolic Regression Models},
  author = {Nicolau, Miguel and Agapitos, Alexandros and Agapitos, Alexandros},
  date = {2021-03-01},
  journaltitle = {Genetic Programming and Evolvable Machines},
  volume = {22},
  number = {1},
  pages = {73--100},
  doi = {10.1007/s10710-020-09391-4},
  abstract = {Supervised learning by means of Genetic Programming (GP) aims at the evolutionary synthesis of a model that achieves a balance between approximating the target function on the training data and generalising on new data. The model space searched by the Evolutionary Algorithm is populated by compositions of primitive functions defined in a function set. Since the target function is unknown, the choice of function set’s constituent elements is primarily guided by the makeup of function sets traditionally used in the GP literature. Our work builds upon previous research of the effects of protected arithmetic operators (i.e. division, logarithm, power) on the output value of an evolved model for input data points not encountered during training. The scope is to benchmark the approximation/generalisation of models evolved using different function set choices across a range of 43 symbolic regression problems. The salient outcomes are as follows. Firstly, Koza’s protected operators of division and exponentiation have a detrimental effect on generalisation, and should therefore be avoided. This result is invariant of the use of moderately sized validation sets for model selection. Secondly, the performance of the recently introduced analytic quotient operator is comparable to that of the sinusoidal operator on average, with their combination being advantageous to both approximation and generalisation. These findings are consistent across two different system implementations, those of standard expression-tree GP and linear Grammatical Evolution. We highlight that this study employed very large test sets, which create confidence when benchmarking the effect of different combinations of primitive functions on model generalisation. Our aim is to encourage GP researchers and practitioners to use similar stringent means of assessing generalisation of evolved models where possible, and also to avoid certain primitive functions that are known to be inappropriate.},
  annotation = {MAG ID: 3025201237}
}

@book{poliFieldGuideGenetic2008,
  title = {A Field Guide to Genetic Programming},
  author = {Poli, Riccardo and Langdon, William B. and McPhee, Nicholas F. and Koza, John R.},
  date = {2008},
  publisher = {{Lulu Press]}},
  location = {{[Morrisville, NC}},
  isbn = {978-1-4092-0073-4},
  langid = {english},
  pagetotal = {233}
}

@article{qichenFeatureSelectionImprove2017,
  title = {Feature {{Selection}} to {{Improve Generalization}} of {{Genetic Programming}} for {{High-Dimensional Symbolic Regression}}},
  author = {{Qi Chen} and Chen, Qi and Zhang, Mengjie and Xue, Bing},
  date = {2017-03-16},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  volume = {21},
  number = {5},
  pages = {792--806},
  doi = {10.1109/tevc.2017.2683489},
  abstract = {When learning from high-dimensional data for symbolic regression (SR), genetic programming (GP) typically could not generalize well. Feature selection, as a data preprocessing method, can potentially contribute not only to improving the efficiency of learning algorithms but also to enhancing the generalization ability. However, in GP for high-dimensional SR, feature selection before learning is seldom considered. In this paper, we propose a new feature selection method based on permutation to select features for high-dimensional SR using GP. A set of experiments has been conducted to investigate the performance of the proposed method on the generalization of GP for high-dimensional SR. The regression results confirm the superior performance of the proposed method over the other examined feature selection methods. Further analysis indicates that the models evolved by the proposed method are more likely to contain only the truly relevant features and have better interpretability.},
  annotation = {MAG ID: 2595303237}
}

@article{qichenImprovingGeneralisationGenetic2016,
  title = {Improving Generalisation of Genetic Programming for High-Dimensional Symbolic Regression with Feature Selection},
  author = {{Qi Chen} and Chen, Qi and Xue, Bing and Niu, Ben and {Ben Niu} and Zhang, Mengjie},
  date = {2016-07-01},
  pages = {3793--3800},
  doi = {10.1109/cec.2016.7744270},
  abstract = {Feature selection is a desired process when learning from high-dimensional data. However, it is seldom considered in Genetic Programming (GP) for high-dimensional symbolic regression. This work aims to develop a new method, Genetic Programming with Feature Selection (GPWFS), to improve the generalisation ability of GP for symbolic regression. GPWFS is a two-stage method. The main task of the first stage is to select important/informative features from fittest individuals, and the second stage uses a set of selected features, which is a subset of original features, for regression. To investigate the learning/optimisation performance and generalisation capability of GPWFS, a set of experiments using standard GP as a baseline for comparison have been conducted on six real-world high-dimensional symbolic regression datasets. The experimental results show that GPWFS can have better performance both on the training sets and the test sets on most cases. Further analysis on the solution size, the number of distinguished features and total number of used features in the evolved models shows that using GPWFS can induce more compact models with better interpretability and lower computational costs than standard GP.},
  annotation = {MAG ID: 2558896678}
}

@article{qichenImprovingGeneralizationGenetic2019,
  title = {Improving {{Generalization}} of {{Genetic Programming}} for {{Symbolic Regression With Angle-Driven Geometric Semantic Operators}}},
  author = {{Qi Chen} and Chen, Qi and Xue, Bing and Zhang, Mengjie},
  date = {2019-06-01},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  volume = {23},
  number = {3},
  pages = {488--502},
  doi = {10.1109/tevc.2018.2869621},
  abstract = {Geometric semantic genetic programming (GP) has recently attracted much attention. The key innovations are inducing a unimodal fitness landscape in the semantic space and providing a theoretical framework for designing geometric semantic operators. The geometric semantic operators aim to manipulate the semantics of programs by making a bounded semantic impact and generating child programs with similar or better behavior than their parents. These properties are shown to be highly related to a notable generalization improvement in GP. However, the potential ineffectiveness and difficulties in bounding the variations in these geometric operators still limits their positive effect on generalization. This paper attempts to further explore the geometry and search space of geometric operators to gain a greater generalization improvement in GP for symbolic regression. To this end, a new angle-driven selection operator and two new angle-driven geometric search operators are proposed. The angle-awareness brings new geometric properties to these geometric operators, which are expected to provide a greater leverage for approximating the target semantics in each operation, and more importantly, be resistant to overfitting. The experiments show that compared with two state-of-the-art geometric semantic operators, our angle-driven geometric operators not only drive the evolutionary process to fit the target semantics more efficiently but also improve the generalization performance. A further comparison between the evolved models shows that the new method generally produces simpler models with a much smaller size and is more likely to evolve toward the correct structure of the target models.},
  annotation = {MAG ID: 2891680306}
}

@article{qichenImprovingSymbolicRegression2020,
  title = {Improving Symbolic Regression Based on Correlation between Residuals and Variables},
  author = {{Qi Chen} and Chen, Qi and Xue, Bing and Zhang, Mengjie},
  date = {2020-06-25},
  pages = {922--930},
  doi = {10.1145/3377930.3390161},
  annotation = {MAG ID: 3039182316}
}

@article{qichenStructuralRiskMinimizationDriven2019,
  title = {Structural {{Risk Minimization-Driven Genetic Programming}} for {{Enhancing Generalization}} in {{Symbolic Regression}}},
  author = {{Qi Chen} and Chen, Qi and Zhang, Mengjie and Xue, Bing},
  date = {2019-08-01},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  volume = {23},
  number = {4},
  pages = {703--717},
  doi = {10.1109/tevc.2018.2881392},
  abstract = {Generalization ability, which reflects the prediction ability of a learned model, is an important property in genetic programming (GP) for symbolic regression. Structural risk minimization (SRM) is a framework providing a reliable estimation of the generalization performance of prediction models. Introducing the framework into GP has the potential to drive the evolutionary process toward models with good generalization performance. However, this is tough due to the difficulty in obtaining the Vapnik–Chervonenkis (VC) dimension of nonlinear models. To address this difficulty, this paper proposes an SRM-driven GP approach, which uses an  experimental  method (instead of theoretical estimation) to measure the VC dimension of a mixture of linear and nonlinear regression models for the first time. The  experimental  method has been conducted using uniform and nonuniform settings. The results show that our method has impressive generalization gains over standard GP and GP with the 0.632 bootstrap, and that the proposed method using the nonuniform setting has further improvement than its counterpart using the uniform setting. Further analyzes reveal that the proposed method can evolve more compact models, and that the behavioral difference between these compact models and the target models is much smaller than their counterparts evolved by the other GP methods.},
  annotation = {MAG ID: 2901725080}
}

@inproceedings{raymondAdaptiveWeightedSplines2020,
  title = {Adaptive Weighted Splines: A New Representation to Genetic Programming for Symbolic Regression},
  shorttitle = {Adaptive Weighted Splines},
  booktitle = {Proceedings of the 2020 {{Genetic}} and {{Evolutionary Computation Conference}}},
  author = {Raymond, Christian and Chen, Qi and Xue, Bing and Zhang, Mengjie},
  date = {2020-06-25},
  series = {{{GECCO}} '20},
  pages = {1003--1011},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3377930.3390244},
  url = {https://doi.org/10.1145/3377930.3390244},
  urldate = {2022-04-29},
  abstract = {Genetic Programming for Symbolic Regression is often prone to overfit the training data, resulting in poor generalization on unseen data. To address this issue, many pieces of research have been devoted to regularization via controlling the model complexity. However, due to the unstructured tree based representation of individuals the model complexity cannot be directly computed, rather approximation of the complexity must be taken. This paper proposes a new novel representation called Adaptive Weighted Splines which enables explicit control over the complexity of individuals using splines. The experimental results confirm that this new representation is significantly better than the tree-based representation at avoiding overfitting and generalizing on unseen data, demonstrating notably better and far more consistent generalization performances on all the benchmark problems. Further analysis also shows that in most cases, the new Genetic Programming method outperforms classical regression techniques such as Linear Regression, Support Vector Regression, K-Nearest Neighbour and Decision Tree Regression and performs competitively with state-of-the-art ensemble regression methods Random Forests and Gradient Boosting.},
  isbn = {978-1-4503-7128-5},
  keywords = {generalization,genetic programming,representation,spline,symbolic regression}
}

@article{raymondMultiobjectiveGeneticProgramming2021,
  title = {Multi-Objective Genetic Programming for Symbolic Regression with the Adaptive Weighted Splines Representation},
  author = {Raymond, Christian and Chen, Qi and Xue, Bing and Zhang, Mengjie},
  date = {2021-07-07},
  pages = {165--166},
  doi = {10.1145/3449726.3459461},
  abstract = {Genetic Programming (GP) for symbolic regression often generates over-complex models, which overfit the training data and have poor generalization onto unseen data. One recent work investigated controlling model complexity by using a new GP representation called Adaptive Weighted Splines (AWS), which is a semi-structured representation that can control the model complexity explicitly. This work extends this previous work by incorporating a new parsimony pressure objective to further control the model complexity. Experimental results demonstrate that the new multi-objective GP method consistently obtains superior fronts and produces better generalizing models compared to single-objective GP with both the tree-based and AWS representation as well a multi-objective tree-based GP method with parsimony pressure.},
  annotation = {MAG ID: 3179367438}
}

@incollection{shannonProgrammingComputerPlaying1988,
  title = {Programming a {{Computer}} for {{Playing Chess}}},
  booktitle = {Computer {{Chess Compendium}}},
  author = {Shannon, Claude E.},
  editor = {Levy, David},
  date = {1988},
  pages = {2--13},
  publisher = {{Springer New York}},
  location = {{New York, NY}},
  doi = {10.1007/978-1-4757-1968-0_1},
  url = {http://link.springer.com/10.1007/978-1-4757-1968-0_1},
  urldate = {2022-04-26},
  isbn = {978-1-4757-1970-3 978-1-4757-1968-0},
  langid = {english}
}

@inproceedings{sithunguUsingGeneticProgramming2019,
  title = {Using {{Genetic Programming}} and {{Decision Trees}} for {{Team Evolution}}},
  booktitle = {Proceedings of the 2019 2nd {{International Conference}} on {{Computational Intelligence}} and {{Intelligent Systems}}},
  author = {Sithungu, Siphesihle Philezwini and Coulter, Duncan Anthony and Ehlers, Elizabeth Marie},
  date = {2019-11-23},
  series = {{{CIIS}} 2019},
  pages = {28--39},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3372422.3372430},
  url = {https://doi.org/10.1145/3372422.3372430},
  urldate = {2022-04-20},
  abstract = {This paper presents work done to evolve soccer strategies through Genetic Programming. Each agent is controlled by an algorithm in the form of a decision tree to act on the environment given its percepts. Several experiments were performed and an analysis of the performance of the algorithm was documented afterwards. Experimental results showed that it is possible to implement soccer learning in a multi-agent system through Genetic Programming, although the evolution of higher-level soccer strategies is a more difficult task.},
  isbn = {978-1-4503-7259-6},
  keywords = {decision trees,evolutionary learning,genetic programming}
}

@inproceedings{skinnerArtificialIntelligenceDeep2019,
  title = {Artificial {{Intelligence}} and {{Deep Learning}} in {{Video Games A Brief Review}}},
  booktitle = {2019 {{IEEE}} 4th {{International Conference}} on {{Computer}} and {{Communication Systems}} ({{ICCCS}})},
  author = {Skinner, Geoff and Walmsley, Toby},
  date = {2019-02},
  pages = {404--408},
  doi = {10.1109/CCOMS.2019.8821783},
  abstract = {Artificial Intelligence has been used in many fields since the term was coined six decades ago. Artificial Intelligence in video games was introduced with Atari 2600's early titles such as `Computer Space' and `Pong' and has come a long way since. However, it has become expected of developers to have flawless AI which is as human-like as possible. Neural Networks are allowing AI systems to become smarter and used in ways such as OpenAI does with their game-playing bots. Many game-playing Neural Networks use reinforcement learning to train as it allows for more efficient training for larger games where the number of possible positions and combinations of game mechanics are extremely large. This paper provides an introductory literature review of these core fields of research as they applied within a video game context.},
  eventtitle = {2019 {{IEEE}} 4th {{International Conference}} on {{Computer}} and {{Communication Systems}} ({{ICCCS}})},
  keywords = {artificial intelligence,deep learning,Deep learning,Games,neural networks,Neural networks,Robots,Testing,video games}
}

@inproceedings{thekumparampilEfficientAlgorithmsSmooth2019,
  title = {Efficient {{Algorithms}} for {{Smooth Minimax Optimization}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Thekumparampil, Kiran K and Jain, Prateek and Netrapalli, Praneeth and Oh, Sewoong},
  date = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2019/hash/05d0abb9a864ae4981e933685b8b915c-Abstract.html},
  urldate = {2022-04-20}
}

@inproceedings{torradoDeepReinforcementLearning2018,
  title = {Deep {{Reinforcement Learning}} for {{General Video Game AI}}},
  booktitle = {2018 {{IEEE Conference}} on {{Computational Intelligence}} and {{Games}} ({{CIG}})},
  author = {Torrado, Ruben Rodriguez and Bontrager, Philip and Togelius, Julian and Liu, Jialin and Perez-Liebana, Diego},
  date = {2018-08},
  pages = {1--8},
  issn = {2325-4289},
  doi = {10.1109/CIG.2018.8490422},
  abstract = {The General Video Game AI (GVGAI) competition and its associated software framework provides a way of benchmarking AI algorithms on a large number of games written in a domain-specific description language. While the competition has seen plenty of interest, it has so far focused on online planning, providing a forward model that allows the use of algorithms such as Monte Carlo Tree Search. In this paper, we describe how we interface GVGAI to the OpenAI Gym environment, a widely used way of connecting agents to reinforcement learning problems. Using this interface, we characterize how widely used implementations of several deep reinforcement learning algorithms fare on a number of GVGAI games. We further analyze the results to provide a first indication of the relative difficulty of these games relative to each other, and relative to those in the Arcade Learning Environment under similar conditions.},
  eventtitle = {2018 {{IEEE Conference}} on {{Computational Intelligence}} and {{Games}} ({{CIG}})},
  keywords = {advantage actor critic,Benchmark testing,deep Q-learning,deep reinforcement learning,Games,general video game AI,Learning (artificial intelligence),Machine learning,OpenAI Gym,Planning,video game description language}
}

@article{turingCOMPUTINGMACHINERYINTELLIGENCE1950,
  title = {I.—{{COMPUTING MACHINERY AND INTELLIGENCE}}},
  author = {Turing, A. M.},
  date = {1950-10-01},
  journaltitle = {Mind},
  volume = {LIX},
  number = {236},
  pages = {433--460},
  issn = {1460-2113, 0026-4423},
  doi = {10.1093/mind/LIX.236.433},
  url = {https://academic.oup.com/mind/article/LIX/236/433/986238},
  urldate = {2022-04-20},
  langid = {english}
}

@article{uyImprovingGeneralisationAbility2010,
  title = {Improving the Generalisation Ability of Genetic Programming with Semantic Similarity Based Crossover},
  author = {Uy, Nguyen Quang and Hien, Nguyen Thi and Hoai, Nguyen Xuan and O'Neill, Michael},
  date = {2010-04-07},
  pages = {184--195},
  doi = {10.1007/978-3-642-12148-7_16},
  abstract = {This paper examines the impact of semantic control on the ability of Genetic Programming (GP) to generalise via a semantic based crossover operator (Semantic Similarity based Crossover - SSC). The use of validation sets is also investigated for both standard crossover and SSC. All GP systems are tested on a number of real-valued symbolic regression problems. The experimental results show that while using validation sets barely improve generalisation ability of GP, by using semantics, the performance of Genetic Programming is enhanced both on training and testing data. Further recorded statistics shows that the size of the evolved solutions by using SSC are often smaller than ones obtained from GP systems that do not use semantics. This can be seen as one of the reasons for the success of SSC in improving the generalisation ability of GP.},
  annotation = {MAG ID: 1524954660}
}

@article{v.neumannZurTheorieGesellschaftsspiele1928,
  title = {Zur Theorie der Gesellschaftsspiele},
  author = {v. Neumann, J.},
  options = {useprefix=true},
  date = {1928-12},
  journaltitle = {Mathematische Annalen},
  shortjournal = {Math. Ann.},
  volume = {100},
  number = {1},
  pages = {295--320},
  issn = {0025-5831, 1432-1807},
  doi = {10.1007/BF01448847},
  url = {http://link.springer.com/10.1007/BF01448847},
  urldate = {2022-04-24},
  langid = {german}
}

@article{wangMultiobjectiveFeatureSelection2020,
  title = {Multi-Objective Feature Selection Based on Artificial Bee Colony: {{An}} Acceleration Approach with Variable Sample Size},
  author = {Wang, Xiao-han and Zhang, Yong and Sun, Xiaoyan and Sun, Xiaoyan and Wang, Yong-li and Du, Chang-he},
  date = {2020-03-01},
  journaltitle = {Applied Soft Computing},
  volume = {88},
  pages = {106041},
  doi = {10.1016/j.asoc.2019.106041},
  abstract = {Abstract   Due to the need to repeatedly call a classifier to evaluate individuals in the population, existing evolutionary feature selection algorithms have the disadvantage of high computational cost. In view of it, this paper studies a multi-objective feature selection framework based on sample reduction strategy and evolutionary algorithm, significantly reducing the computational cost of algorithm without affecting optimal results. In the framework, a selection strategy of representative samples, called K-means clustering based differential selection, and a ladder-like sample utilization strategy are proposed to reduce the size of samples used in the evolutionary process. Moreover, a fast multi-objective evolutionary feature selection algorithm, called FMABC-FS, is proposed by embedding an improved artificial bee colony algorithm based on the particle update model into the framework. By applying FMABC-FS to several typical UCI datasets, and comparing with three multi-objective feature selection algorithms, experimental results show that the proposed variable sample size strategy is more suitable to FMABC-FS, and FMABC-FS can obtain better feature subsets with much less running time than those comparison algorithms.},
  annotation = {MAG ID: 2996901426}
}

@unpublished{wangSolvingMinimaxOptimization2019,
  title = {On {{Solving Minimax Optimization Locally}}: {{A Follow-the-Ridge Approach}}},
  shorttitle = {On {{Solving Minimax Optimization Locally}}},
  author = {Wang, Yuanhao and Zhang, Guodong and Ba, Jimmy},
  date = {2019-11-25},
  eprint = {1910.07512},
  eprinttype = {arxiv},
  primaryclass = {cs, math, stat},
  url = {http://arxiv.org/abs/1910.07512},
  urldate = {2022-04-20},
  abstract = {Many tasks in modern machine learning can be formulated as finding equilibria in \textbackslash emph\{sequential\} games. In particular, two-player zero-sum sequential games, also known as minimax optimization, have received growing interest. It is tempting to apply gradient descent to solve minimax optimization given its popularity and success in supervised learning. However, it has been noted that naive application of gradient descent fails to find some local minimax and can converge to non-local-minimax points. In this paper, we propose \textbackslash emph\{Follow-the-Ridge\} (FR), a novel algorithm that provably converges to and only converges to local minimax. We show theoretically that the algorithm addresses the notorious rotational behaviour of gradient dynamics, and is compatible with preconditioning and \textbackslash emph\{positive\} momentum. Empirically, FR solves toy minimax problems and improves the convergence of GAN training compared to the recent minimax optimization algorithms.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning}
}

@online{wilhelmstotterJeneticsJavaGenetic,
  title = {Jenetics: {{Java Genetic Algorithm Library}}},
  shorttitle = {Jenetics},
  author = {Wilhelmstötter, Franz},
  url = {https://jenetics.io/},
  urldate = {2022-04-20},
  abstract = {Jenetics is a Genetic Algorithm, Evolutionary Algorithm, Genetic Programming, and Multi-objective Optimization library, written in modern-day Java.},
  langid = {english},
  organization = {{jenetics.io}}
}

@inreference{ZerosumGame2022,
  title = {Zero-Sum Game},
  booktitle = {Wikipedia},
  date = {2022-04-05T01:11:03Z},
  url = {https://en.wikipedia.org/w/index.php?title=Zero-sum_game&oldid=1081052640},
  urldate = {2022-04-18},
  abstract = {Zero-sum game is a mathematical representation in game theory and economic theory of a situation which involves two sides, where the result is an advantage for one side and an equivalent loss for the other.If the total gains of the participants are added up, and the total losses are subtracted, they will sum to zero. Thus, cutting a cake, where taking a more significant piece reduces the amount of cake available for others as much as it increases the amount available for that taker, is a zero-sum game if all participants value each unit of cake equally. Other examples of zero-sum games in daily life include games like poker, chess, and bridge where one person gains and another person loses, which results in a zero-net benefit for every player. In the markets and financial instruments, futures contracts and options are zero-sum games as well. Nevertheless, the situation like the stock market etc. is not a zero-sum game because investors could gain profit or loss from share price influences by profit forecasts or economic outlooks rather than gain profit from other investors' losses. In contrast, non-zero-sum describes a situation in which the interacting parties' aggregate gains and losses can be less than or more than zero. A zero-sum game is also called a strictly competitive game, while non-zero-sum games can be either competitive or non-competitive. Zero-sum games are most often solved with the minimax theorem which is closely related to linear programming duality, or with Nash equilibrium. Prisoner's Dilemma is a classical non-zero-sum game.},
  langid = {english},
  annotation = {Page Version ID: 1081052640}
}

@article{zhangRLGEPSymbolicRegression2021,
  title = {{{RL-GEP}}: {{Symbolic Regression}} via {{Gene Expression Programming}} and {{Reinforcement Learning}}},
  author = {Zhang, Hengzhe and {Hengzhe Zhang} and Zhou, Aimin and {Aimin Zhou} and {Aimin Zhou}},
  date = {2021-07-18},
  pages = {1--8},
  doi = {10.1109/ijcnn52387.2021.9533735},
  abstract = {Symbolic regression has become a hot topic in recent years due to the surging demand for interpretable machine learning methods. Traditionally, symbolic regression problems are mainly solved by genetic algorithms. Nonetheless, with the development of deep learning, reinforcement learning based symbolic regression methods have received attention gradually. Unfortunately, hardly any of those reinforcement learning based methods have been proven effectively to solve real world regression problems as genetic algorithm based methods. In this paper, we find a general reinforcement learning based symbolic regression method is difficult to solve real world problems since it is hard to balance between exploration and exploitation. To deal with this problem, we propose a hybrid method to use both genetic algorithm and reinforcement learning for solving symbolic regression problems. By doing so, we can combine the advantages of reinforcement learning and genetic algorithm and achieve better performance than using them alone. To validate the effectiveness of the proposed method, we apply the proposed method to ten benchmark datasets. The experimental results show that the proposed method achieves competitive performance compared with several well-known symbolic regression methods on those datasets.},
  annotation = {MAG ID: 3200734637}
}

@preamble{ "\ifdefined\DeclarePrefChars\DeclarePrefChars{'’-}\else\fi " }

