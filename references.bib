
@online{noauthor_minimax_nodate,
	title = {Minimax - Wikipedia},
	url = {https://en.wikipedia.org/wiki/Minimax},
	urldate = {2022-04-18},
	file = {Minimax - Wikipedia:C\:\\Users\\LEGION\\Zotero\\storage\\LYU3UGLI\\Minimax.html:text/html},
}

@article{fan_minimax_1953,
	title = {Minimax Theorems},
	volume = {39},
	issn = {0027-8424},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1063722/},
	pages = {42--47},
	number = {1},
	journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
	shortjournal = {Proc Natl Acad Sci U S A},
	author = {Fan, Ky},
	urldate = {2022-04-18},
	date = {1953-01},
	pmid = {16589233},
	pmcid = {PMC1063722},
	file = {Fan - 1953 - Minimax Theorems.pdf:C\:\\Users\\LEGION\\Zotero\\storage\\SRJ7LJ63\\Fan - 1953 - Minimax Theorems.pdf:application/pdf},
}

@software{magarena_community_magarenamagarena_2022,
	title = {magarena/magarena},
	rights = {{GPL}-3.0},
	url = {https://github.com/magarena/magarena},
	abstract = {Magarena is a single-player fantasy card game played against a computer opponent.},
	publisher = {{MagArena}},
	editora = {{Magarena Community}},
	editoratype = {collaborator},
	urldate = {2022-04-18},
	date = {2022-04-14},
	note = {original-date: 2014-01-26T10:14:56Z},
	keywords = {card, game},
}

@book{maschler_game_2013,
	location = {Cambridge},
	title = {Game Theory},
	isbn = {978-0-511-79421-6},
	url = {http://ebooks.cambridge.org/ref/id/CBO9780511794216},
	publisher = {Cambridge University Press},
	author = {Maschler, Michael and Solan, Eilon and Zamir, Shmuel},
	urldate = {2022-04-18},
	date = {2013},
	doi = {10.1017/CBO9780511794216},
}

@inreference{noauthor_evaluation_2022,
	title = {Evaluation function},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Evaluation_function&oldid=1079533564},
	abstract = {An evaluation function, also known as a heuristic evaluation function or static evaluation function, is a function used by game-playing computer programs to estimate the value or goodness of a position (usually at a leaf or terminal node) in a game tree. Most of the time, the value is either a real number or a quantized integer, often in nths of the value of a playing piece such as a stone in go or a pawn in chess, where n may be tenths, hundredths or other convenient fraction, but sometimes, the value is an array of three values in the unit interval, representing the win, draw, and loss percentages of the position. 
There do not exist analytical or theoretical models for evaluation functions for unsolved games, nor are such functions entirely ad-hoc.  The composition of evaluation functions is determined empirically by inserting a candidate function into an automaton and evaluating its subsequent performance.  A significant body of evidence now exists for several games like chess, shogi and go as to the general composition of evaluation functions for them.
Games in which game playing computer programs employ evaluation functions include chess, go, shogi (Japanese chess), othello, hex, backgammon, and checkers. In addition, with the advent of programs such as {MuZero}, computer programs also use evaluation functions to play video games, such as those from the Atari 2600. Some games like tic-tac-toe are strongly solved, and do not require search or evaluation because a discrete solution tree is available.},
	booktitle = {Wikipedia},
	urldate = {2022-04-18},
	date = {2022-03-27},
	langid = {english},
	note = {Page Version {ID}: 1079533564},
	file = {Snapshot:C\:\\Users\\LEGION\\Zotero\\storage\\MQ77D2FG\\Evaluation_function.html:text/html},
}

@inreference{noauthor_minimax_2022,
	title = {Minimax},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Minimax&oldid=1076761456},
	abstract = {Minimax (sometimes {MinMax}, {MM} or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for minimizing the possible loss for a worst case (maximum loss) scenario.  When dealing with gains, it is referred to as "maximin"—to maximize the minimum gain.  Originally formulated for n-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been extended to more complex games and to general decision-making in the presence of uncertainty.},
	booktitle = {Wikipedia},
	urldate = {2022-04-18},
	date = {2022-03-12},
	langid = {english},
	note = {Page Version {ID}: 1076761456},
	file = {Snapshot:C\:\\Users\\LEGION\\Zotero\\storage\\EIIGI2V3\\Minimax.html:text/html},
}

@inreference{noauthor_zero-sum_2022,
	title = {Zero-sum game},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Zero-sum_game&oldid=1081052640},
	abstract = {Zero-sum game is a mathematical representation in game theory and economic theory of a situation which involves two sides, where the result is an advantage for one side and an equivalent loss for the other.If the total gains of the participants are added up, and the total losses are subtracted, they will sum to zero. Thus, cutting a cake, where taking a more significant piece reduces the amount of cake available for others as much as it increases the amount available for that taker, is a zero-sum game if all participants value each unit of cake equally. Other examples of zero-sum games in daily life include games like poker, chess, and bridge where one person gains and another person loses, which results in a zero-net benefit for every player. In the markets and financial instruments, futures contracts and options are zero-sum games as well. Nevertheless, the situation like the stock market etc. is not a zero-sum game because investors could gain profit or loss from share price influences by profit forecasts or economic outlooks rather than gain profit from other investors' losses.
In contrast, non-zero-sum describes a situation in which the interacting parties' aggregate gains and losses can be less than or more than zero. A zero-sum game is also called a strictly competitive game, while non-zero-sum games can be either competitive or non-competitive. Zero-sum games are most often solved with the minimax theorem which is closely related to linear programming duality, or with Nash equilibrium. Prisoner's Dilemma is a classical non-zero-sum game.},
	booktitle = {Wikipedia},
	urldate = {2022-04-18},
	date = {2022-04-05},
	langid = {english},
	note = {Page Version {ID}: 1081052640},
	file = {Snapshot:C\:\\Users\\LEGION\\Zotero\\storage\\FJMN24P8\\Zero-sum_game.html:text/html},
}

@article{turing_icomputing_1950,
	title = {I.—{COMPUTING} {MACHINERY} {AND} {INTELLIGENCE}},
	volume = {{LIX}},
	issn = {1460-2113, 0026-4423},
	url = {https://academic.oup.com/mind/article/LIX/236/433/986238},
	doi = {10.1093/mind/LIX.236.433},
	pages = {433--460},
	number = {236},
	journaltitle = {Mind},
	author = {Turing, A. M.},
	urldate = {2022-04-20},
	date = {1950-10-01},
	langid = {english},
	file = {http___www.cs.umbc.edu_471_papers_turing.pdf:C\:\\Users\\LEGION\\Zotero\\storage\\CZUC5DWK\\http___www.cs.umbc.edu_471_papers_turing.pdf:application/pdf},
}

@inreference{noauthor_genetic_2022,
	title = {Genetic programming},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Genetic_programming&oldid=1083071637},
	abstract = {In artificial intelligence, genetic programming ({GP}) is a technique of evolving programs, starting from a population of unfit (usually random) programs, fit for a particular task by applying operations analogous to natural genetic processes to the population of programs.
The operations are: selection of the fittest programs for reproduction (crossover) and mutation according to a predefined fitness measure, usually proficiency at the desired task.  The crossover operation involves swapping random parts of selected pairs (parents) to produce new and different offspring that become part of the new generation of programs.  Mutation involves substitution of some random part of a program with some other random part of a program. Some programs not selected for reproduction are copied from the current generation to the new generation. Then the selection and other operations are recursively applied to the new generation of programs.
Typically, members of each new generation are on average more fit than the members of the previous generation, and the best-of-generation program is often better than the best-of-generation programs from previous generations.  Termination of the evolution usually occurs when some individual program reaches a predefined proficiency or fitness level.
It may and often does happen that a particular run of the algorithm results in premature convergence to some local maximum which is not a globally optimal or even good solution.  Multiple runs (dozens to hundreds) are usually necessary to produce a very good result.  It may also be necessary to increase the starting population size and variability of the individuals to avoid pathologies.},
	booktitle = {Wikipedia},
	urldate = {2022-04-20},
	date = {2022-04-16},
	langid = {english},
	note = {Page Version {ID}: 1083071637},
	file = {Snapshot:C\:\\Users\\LEGION\\Zotero\\storage\\SSU6Y9EI\\Genetic_programming.html:text/html},
}

@online{noauthor_non-linear_nodate,
	title = {Non-Linear Genetic Algorithms for Solving Problems},
	url = {http://gpbib.cs.ucl.ac.uk/gp-html/Koza_1990_pat-GAsp.html},
	urldate = {2022-04-20},
	file = {Non-Linear Genetic Algorithms for Solving Problems:C\:\\Users\\LEGION\\Zotero\\storage\\Q47TV7CW\\Koza_1990_pat-GAsp.html:text/html},
}

@online{noauthor_genetic_nodate,
	title = {Genetic Programming: On the Programming of Computers by Means of Natural Selection},
	url = {http://gpbib.cs.ucl.ac.uk/gp-html/koza_book.html},
	urldate = {2022-04-20},
	file = {Genetic Programming\: On the Programming of Computers by Means of Natural Selection:C\:\\Users\\LEGION\\Zotero\\storage\\282JTI8L\\koza_book.html:text/html},
}

@article{forsyth_beagle_1981,
	title = {\textit{{BEAGLE}} —A {DARWINIAN} {APPROACH} {TO} {PATTERN} {RECOGNITION}},
	volume = {10},
	issn = {0368-492X},
	url = {https://www.emerald.com/insight/content/doi/10.1108/eb005587/full/html},
	doi = {10.1108/eb005587},
	abstract = {{BEAGLE} (Biological Evolutionary Algorithm Generating Logical Expressions) is a computer package for producing decision‐rules by induction from a database. It works on the principle of “Naturalistic Selection” whereby rules that fit the data badly are “killed off” and replaced by “mutations” of better rules or by new rules created by “mating” two better adapted rules. The rules are Boolean expressions represented by tree structures. The software consists of two
              Pascal
              programs,
              {HERB}
              (Heuristic Evolutionary Rule Breeder) and
              {LEAF}
              (Logical Evaluator And Forecaster).
              {HERB}
              improves a given starting set of rules by running over several simulated generations.
              {LEAF}
              uses the rules to classify samples from a database where the correct membership may not be known. Preliminary tests on three different databases have been carried out—on hospital admissions (classing heart patients as deaths or survivors), on athletic physique (classing Olympic finalists as long‐distance runners or sprinters) and on football results (categorizing games into draws and non‐draws). It appears from the tests that the method works better than the standard discriminant analysis technique based on a linear discriminant function, and hence that this long‐neglected approach warrants further investigation.},
	pages = {159--166},
	number = {3},
	journaltitle = {Kybernetes},
	author = {Forsyth, Richard},
	urldate = {2022-04-20},
	date = {1981-03-01},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\LEGION\\Zotero\\storage\\WTRF4Z4A\\Forsyth - 1981 - BEAGLE —A DARWINIAN APPROACH TO PATTERN REC.pdf:application/pdf},
}

@online{noauthor_genetic_nodate-1,
	title = {Genetic Programming -- An Introduction; On the Automatic Evolution of Computer Programs and its Applications},
	url = {http://gpbib.cs.ucl.ac.uk/gp-html/banzhaf_1997_book.html},
	urldate = {2022-04-20},
	file = {Genetic Programming -- An Introduction\; On the Automatic Evolution of Computer Programs and its Applications:C\:\\Users\\LEGION\\Zotero\\storage\\RPRUQ6TG\\banzhaf_1997_book.html:text/html},
}

@incollection{koza_genetic_2005,
	location = {Boston, {MA}},
	title = {Genetic Programming},
	isbn = {978-0-387-28356-2},
	url = {https://doi.org/10.1007/0-387-28356-0_5},
	abstract = {The goal of getting computers to automatically solve problems is central to artificial intelligence, machine learning, and the broad area encompassed by what Turing called “machine intelligence„ (Turing, 1948, 1950). In his talk entitled {AI}: Where It Has Been and Where It Is Going, machine learning pioneer Arthur Samuel stated the main goal of the fields of machine learning and artificial intelligence: [T]he aim [is]... to get machines to exhibit behavior, which if done by humans, would be assumed to involve the use of intelligence. (Samuel, 1983) Genetic programming is a systematic method for getting computers to automatically solve a problem starting from a high-level statement of what needs to be done. Genetic programming is a domain-independent method that genetically breeds a population of computer programs to solve a problem. Specifically, genetic programming iteratively transforms a population of computer programs into a new generation of programs by applying analogs of naturally occurring genetic operations. This process is illustrated in Figure 5.1.},
	pages = {127--164},
	booktitle = {Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques},
	publisher = {Springer {US}},
	author = {Koza, John R. and Poli, Riccardo},
	editor = {Burke, Edmund K. and Kendall, Graham},
	urldate = {2022-04-20},
	date = {2005},
	langid = {english},
	doi = {10.1007/0-387-28356-0_5},
	keywords = {Crossover Point, Fitness Measure, Genetic Operation, Genetic Programming, Preparatory Step},
}

@book{langdon_foundations_2013,
	title = {Foundations of Genetic Programming},
	isbn = {978-3-662-04726-2},
	abstract = {Genetic programming ({GP}), one of the most advanced forms of evolutionary computation, has been highly successful as a technique for getting computers to automatically solve problems without having to tell them explicitly how. Since its inceptions more than ten years ago, {GP} has been used to solve practical problems in a variety of application fields. Along with this ad-hoc engineering approaches interest increased in how and why {GP} works. This book provides a coherent consolidation of recent work on the theoretical foundations of {GP}. A concise introduction to {GP} and genetic algorithms ({GA}) is followed by a discussion of fitness landscapes and other theoretical approaches to natural and artificial evolution. Having surveyed early approaches to {GP} theory it presents new exact schema analysis, showing that it applies to {GP} as well as to the simpler {GAs}. New results on the potentially infinite number of possible programs are followed by two chapters applying these new techniques.},
	pagetotal = {265},
	publisher = {Springer Science \& Business Media},
	author = {Langdon, William B. and Poli, Riccardo},
	date = {2013-03-09},
	langid = {english},
	note = {Google-Books-{ID}: {zsaqCAAAQBAJ}},
	keywords = {Computers / Artificial Intelligence / General, Computers / Computer Science, Computers / Data Science / General, Computers / Information Technology, Computers / Information Theory, Computers / Programming / Algorithms, Mathematics / Discrete Mathematics},
}

@article{espejo_survey_2010,
	title = {A Survey on the Application of Genetic Programming to Classification},
	volume = {40},
	issn = {1558-2442},
	doi = {10.1109/TSMCC.2009.2033566},
	abstract = {Classification is one of the most researched questions in machine learning and data mining. A wide range of real problems have been stated as classification problems, for example credit scoring, bankruptcy prediction, medical diagnosis, pattern recognition, text categorization, software quality assessment, and many more. The use of evolutionary algorithms for training classifiers has been studied in the past few decades. Genetic programming ({GP}) is a flexible and powerful evolutionary technique with some features that can be very valuable and suitable for the evolution of classifiers. This paper surveys existing literature about the application of genetic programming to classification, to show the different ways in which this evolutionary algorithm can help in the construction of accurate and reliable classifiers.},
	pages = {121--144},
	number = {2},
	journaltitle = {{IEEE} Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Espejo, Pedro G. and Ventura, Sebastián and Herrera, Francisco},
	date = {2010-03},
	note = {Conference Name: {IEEE} Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	keywords = {Classification, Classification tree analysis, Computer science, Data mining, decision trees, Decision trees, ensemble classifiers, Evolutionary computation, feature construction, feature selection, Genetic programming, genetic programming ({GP}), Machine learning, Medical diagnosis, rule-based systems, Supervised learning, Unsupervised learning},
}

@article{ahvanooey_survey_2019,
	title = {A Survey of Genetic Programming and Its Applications},
	volume = {13},
	issn = {1976-7277},
	url = {https://www.koreascience.or.kr/article/JAKO201919761177651.page},
	doi = {10.3837/tiis.2019.04.002},
	abstract = {Genetic Programming ({GP}) is an intelligence technique whereby computer programs are encoded as a set of genes which are evolved utilizing a Genetic Algorithm ({GA}). In other words, the {GP} employs novel optimization techniques to modify computer programs; imitating the way humans develop programs by progressively re-writing them for solving problems automatically. Trial programs are frequently altered in the search for obtaining superior solutions due to the base is {GA}. These are evolutionary search techniques inspired by biological evolution such as mutation, reproduction, natural selection, recombination, and survival of the fittest. The power of {GAs} is being represented by an advancing range of applications; vector processing, quantum computing, {VLSI} circuit layout, and so on. But one of the most significant uses of {GAs} is the automatic generation of programs. Technically, the {GP} solves problems automatically without having to tell the computer specifically how to process it. To meet this requirement, the {GP} utilizes {GAs} to a "population" of trial programs, traditionally encoded in memory as tree-structures. Trial programs are estimated using a "fitness function" and the suited solutions picked for re-evaluation and modification such that this sequence is replicated until a "correct" program is generated. {GP} has represented its power by modifying a simple program for categorizing news stories, executing optical character recognition, medical signal filters, and for target identification, etc. This paper reviews existing literature regarding the {GPs} and their applications in different scientific fields and aims to provide an easy understanding of various types of {GPs} for beginners.},
	pages = {1765--1794},
	number = {4},
	journaltitle = {{KSII} Transactions on Internet and Information Systems ({TIIS})},
	author = {Ahvanooey, Milad Taleby and Li, Qianmu and Wu, Ming and Wang, Shuo},
	urldate = {2022-04-20},
	date = {2019},
	note = {Publisher: Korean Society for Internet Information},
	file = {Full Text PDF:C\:\\Users\\LEGION\\Zotero\\storage\\FARE8WAA\\Ahvanooey et al. - 2019 - A Survey of Genetic Programming and Its Applicatio.pdf:application/pdf},
}

@inproceedings{de_freitas_evolving_2018,
	title = {Evolving Controllers for Mario {AI} Using Grammar-based Genetic Programming},
	doi = {10.1109/CEC.2018.8477698},
	abstract = {Video games mimic real-world situations and they can be used as a benchmark to evaluate computational methods in solving different types of problems. Also, machine learning methods are used nowadays to improve the quality of non-player characters in order (i) to create human like behaviors, and (ii) to increase the hardness of the games. Genetic Programming ({GP}) has presented good results when evolving programs in general. One of the main advantage of {GP} is the availability of the source-code of its solutions, helping researchers to understand the decision-making process. Also, a formal grammar can be used in order to facilitate the generation of programs in more complex languages (such as Java, C, and Python). Here, we propose the use of Grammar-based Genetic Programming ({GGP}) to evolve controllers for Mario {AI}, a popular platform to test video game controllers which simulates the Nintendo's Super Mario Bros. Also, as {GP} provides the source-code of the solutions, we present and analyze the best program obtained. Finally, {GGP} is compared to other techniques from the literature and the results show that {GGP} find good controllers, specially with respect to the scores obtained on higher difficulty levels.},
	eventtitle = {2018 {IEEE} Congress on Evolutionary Computation ({CEC})},
	pages = {1--8},
	booktitle = {2018 {IEEE} Congress on Evolutionary Computation ({CEC})},
	author = {de Freitas, João Marcos and de Souza, Felipe Rafael and Bernardino, Heder S.},
	date = {2018-07},
	keywords = {Genetic programming, Artificial intelligence, Decision making, game controller, Games, Grammar, grammar-based genetic programming, mario ai, Sociology, Statistics},
}

@article{kelly_scaling_2018,
	title = {Scaling Genetic Programming to Challenging Reinforcement Tasks through Emergent Modularity},
	url = {https://DalSpace.library.dal.ca//handle/10222/73979},
	abstract = {Algorithms that learn through environmental interaction and delayed rewards, or reinforcement learning, increasingly face the challenge of scaling to dynamic, high-dimensional environments. Video games model these types of real-world decision-making and control scenarios while being simple enough to implement within experiments. This work demonstrates how emergent modularity and open-ended evolution allow genetic programming ({GP}) to discover strategies for difficult gaming scenarios while maintaining relatively low model complexity. Two related learning algorithms are considered: Policy Trees and Tangled Program Graphs ({TPG}).  
 
In the case of Policy Trees, a methodology for transfer learning is proposed which specifically leverages both structural and behavioural modularity in the learner representation. The utility of the approach is empirically evaluated in two challenging task domains: {RoboCup} Soccer and Ms. Pac-Man. In {RoboCup}, decision-making policies are first evolved for simple subtasks and then reused within a policy hierarchy in order to learn the more complex task of Half-Field Offense. The same methodology is applied to Ms. Pac-Man, in which case the use of task-agnostic diversity maintenance enables the automatic discovery of suitable sub-policies, removing the need for a prior human-specified task decomposition. In both task domains, the final {GP} decision-making policies reach state-of-the-art levels of play while being significantly less complex than solutions from temporal difference methods and neuroevolution.    
 
{TPG} takes a more open-ended approach to modularity, emphasizing the ability to adaptively complexify policies through interaction with the task environment. The challenging Atari video game environment is used to show that this approach builds decision-making policies that broadly match the quality of several deep learning methods while being several orders of magnitude less computationally demanding, both in terms of sample efficiency and model complexity. Finally, the approach is capable of evolving solutions to multiple game titles simultaneously with no additional computational cost. In this case, agent behaviours for an individual game as well as single agents capable of playing up to 5 games emerge from the same evolutionary run.},
	author = {Kelly, Stephen},
	urldate = {2022-04-20},
	date = {2018-06-21},
	langid = {english},
	note = {Accepted: 2018-06-21T16:04:28Z},
	file = {Full Text PDF:C\:\\Users\\LEGION\\Zotero\\storage\\QGC6VSI2\\Kelly - 2018 - Scaling Genetic Programming to Challenging Reinfor.pdf:application/pdf},
}

@inproceedings{sithungu_using_2019,
	location = {New York, {NY}, {USA}},
	title = {Using Genetic Programming and Decision Trees for Team Evolution},
	isbn = {978-1-4503-7259-6},
	url = {https://doi.org/10.1145/3372422.3372430},
	doi = {10.1145/3372422.3372430},
	series = {{CIIS} 2019},
	abstract = {This paper presents work done to evolve soccer strategies through Genetic Programming. Each agent is controlled by an algorithm in the form of a decision tree to act on the environment given its percepts. Several experiments were performed and an analysis of the performance of the algorithm was documented afterwards. Experimental results showed that it is possible to implement soccer learning in a multi-agent system through Genetic Programming, although the evolution of higher-level soccer strategies is a more difficult task.},
	pages = {28--39},
	booktitle = {Proceedings of the 2019 2nd International Conference on Computational Intelligence and Intelligent Systems},
	publisher = {Association for Computing Machinery},
	author = {Sithungu, Siphesihle Philezwini and Coulter, Duncan Anthony and Ehlers, Elizabeth Marie},
	urldate = {2022-04-20},
	date = {2019-11-23},
	keywords = {decision trees, evolutionary learning, genetic programming},
}

@inproceedings{lin_near-optimal_2020,
	title = {Near-Optimal Algorithms for Minimax Optimization},
	url = {https://proceedings.mlr.press/v125/lin20a.html},
	abstract = {This paper resolves a longstanding open question pertaining to the design of near-optimal first-order algorithms for smooth and strongly-convex-strongly-concave minimax problems. Current state-of-the-art first-order algorithms find an approximate Nash equilibrium using O{\textasciitilde}(κx+κy)O{\textasciitilde}(κx+κy){\textbackslash}tilde\{O\}({\textbackslash}kappa\_x+{\textbackslash}kappa\_y) or O{\textasciitilde}(min\{κxκy−−√,κx−−√κy\})O{\textasciitilde}(min\{κxκy,κxκy\}){\textbackslash}tilde\{O\}({\textbackslash}text\{min\}{\textbackslash}\{{\textbackslash}kappa\_x{\textbackslash}sqrt\{{\textbackslash}kappa\_y\}, {\textbackslash}sqrt\{{\textbackslash}kappa\_x\}{\textbackslash}kappa\_y{\textbackslash}\})  gradient evaluations, where κxκx{\textbackslash}kappa\_x and κyκy{\textbackslash}kappa\_y are the condition numbers for the strong-convexity and strong-concavity assumptions. A gap still remains between these results and the best existing lower bound Ω{\textasciitilde}(κxκy−−−−√)Ω{\textasciitilde}(κxκy){\textbackslash}tilde\{{\textbackslash}Omega\}({\textbackslash}sqrt\{{\textbackslash}kappa\_x{\textbackslash}kappa\_y\}).  This paper presents the first algorithm with O{\textasciitilde}(κxκy−−−−√)O{\textasciitilde}(κxκy){\textbackslash}tilde\{O\}({\textbackslash}sqrt\{{\textbackslash}kappa\_x{\textbackslash}kappa\_y\}) gradient complexity, matching the lower bound up to logarithmic factors. Our algorithm is designed based on an accelerated proximal point method and an accelerated solver for minimax proximal steps.  It can be easily extended to the settings of strongly-convex-concave, convex-concave, nonconvex-strongly-concave, and nonconvex-concave functions. This paper also presents algorithms that match or outperform all existing methods in these settings in terms of gradient complexity, up to logarithmic factors.},
	eventtitle = {Conference on Learning Theory},
	pages = {2738--2779},
	booktitle = {Proceedings of Thirty Third Conference on Learning Theory},
	publisher = {{PMLR}},
	author = {Lin, Tianyi and Jin, Chi and Jordan, Michael I.},
	urldate = {2022-04-20},
	date = {2020-07-15},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:C\:\\Users\\LEGION\\Zotero\\storage\\CDE97XGG\\Lin et al. - 2020 - Near-Optimal Algorithms for Minimax Optimization.pdf:application/pdf},
}

@inproceedings{thekumparampil_efficient_2019,
	title = {Efficient Algorithms for Smooth Minimax Optimization},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper/2019/hash/05d0abb9a864ae4981e933685b8b915c-Abstract.html},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Thekumparampil, Kiran K and Jain, Prateek and Netrapalli, Praneeth and Oh, Sewoong},
	urldate = {2022-04-20},
	date = {2019},
	file = {Full Text PDF:C\:\\Users\\LEGION\\Zotero\\storage\\RQGEYLL9\\Thekumparampil et al. - 2019 - Efficient Algorithms for Smooth Minimax Optimizati.pdf:application/pdf},
}

@article{wang_solving_2019,
	title = {On Solving Minimax Optimization Locally: A Follow-the-Ridge Approach},
	url = {http://arxiv.org/abs/1910.07512},
	shorttitle = {On Solving Minimax Optimization Locally},
	abstract = {Many tasks in modern machine learning can be formulated as finding equilibria in {\textbackslash}emph\{sequential\} games. In particular, two-player zero-sum sequential games, also known as minimax optimization, have received growing interest. It is tempting to apply gradient descent to solve minimax optimization given its popularity and success in supervised learning. However, it has been noted that naive application of gradient descent fails to find some local minimax and can converge to non-local-minimax points. In this paper, we propose {\textbackslash}emph\{Follow-the-Ridge\} ({FR}), a novel algorithm that provably converges to and only converges to local minimax. We show theoretically that the algorithm addresses the notorious rotational behaviour of gradient dynamics, and is compatible with preconditioning and {\textbackslash}emph\{positive\} momentum. Empirically, {FR} solves toy minimax problems and improves the convergence of {GAN} training compared to the recent minimax optimization algorithms.},
	journaltitle = {{arXiv}:1910.07512 [cs, math, stat]},
	author = {Wang, Yuanhao and Zhang, Guodong and Ba, Jimmy},
	urldate = {2022-04-20},
	date = {2019-11-25},
	eprinttype = {arxiv},
	eprint = {1910.07512},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\LEGION\\Zotero\\storage\\FRRCYB4L\\Wang et al. - 2019 - On Solving Minimax Optimization Locally A Follow-.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\LEGION\\Zotero\\storage\\ZLFWQ5BK\\1910.html:text/html},
}

@inproceedings{agarwal_model-based_2020,
	title = {Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal},
	url = {https://proceedings.mlr.press/v125/agarwal20b.html},
	abstract = {This work considers the sample and computational complexity of obtaining an ϵϵ{\textbackslash}epsilon-optimal policy in a discounted Markov Decision Process ({MDP}), given only access to a generative model. In this model, the learner accesses the underlying transition model via a sampling oracle that provides a sample of the next state, when given any state-action pair as input. We are interested in a basic and unresolved question in model based planning: is this naïve “plug-in” approach — where we build the maximum likelihood estimate of the transition model in the {MDP} from observations and then find an optimal policy in this empirical {MDP} — non-asymptotically, minimax optimal? Our main result answers this question positively. With regards to computation, our result provides a simpler approach towards minimax optimal planning: in comparison to prior model-free results,  we show that using {\textbackslash}emph\{any\} high accuracy, black-box planning oracle in the empirical model suffices to obtain the minimax error rate. The key proof technique uses a leave-one-out analysis, in a novel “absorbing {MDP}” construction, to decouple the statistical dependency issues that arise in the analysis of model-based planning; this construction may be helpful more generally.},
	eventtitle = {Conference on Learning Theory},
	pages = {67--83},
	booktitle = {Proceedings of Thirty Third Conference on Learning Theory},
	publisher = {{PMLR}},
	author = {Agarwal, Alekh and Kakade, Sham and Yang, Lin F.},
	urldate = {2022-04-20},
	date = {2020-07-15},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:C\:\\Users\\LEGION\\Zotero\\storage\\5UA9NSH3\\Agarwal et al. - 2020 - Model-Based Reinforcement Learning with a Generati.pdf:application/pdf},
}

@inproceedings{lin_gradient_2020,
	title = {On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems},
	url = {https://proceedings.mlr.press/v119/lin20a.html},
	abstract = {We consider nonconvex-concave minimax problems, minxmaxy∈Yf(x,y)minxmaxy∈Yf(x,y){\textbackslash}min\_\{{\textbackslash}mathbf\{x\}\} {\textbackslash}max\_\{{\textbackslash}mathbf\{y\} {\textbackslash}in {\textbackslash}mathcal\{Y\}\} f({\textbackslash}mathbf\{x\}, {\textbackslash}mathbf\{y\}), where fff is nonconvex in xx{\textbackslash}mathbf\{x\} but concave in yy{\textbackslash}mathbf\{y\} and {YY}{\textbackslash}mathcal\{Y\} is a convex and bounded set. One of the most popular algorithms for solving this problem is the celebrated gradient descent ascent ({GDA}) algorithm, which has been widely used in machine learning, control theory and economics. Despite the extensive convergence results for the convex-concave setting, {GDA} with equal stepsize can converge to limit cycles or even diverge in a general setting. In this paper, we present the complexity results on two-time-scale {GDA} for solving nonconvex-concave minimax problems, showing that the algorithm can find a stationary point of the function Φ(⋅):=maxy∈Yf(⋅,y)Φ(⋅):=maxy∈Yf(⋅,y){\textbackslash}Phi({\textbackslash}cdot) := {\textbackslash}max\_\{{\textbackslash}mathbf\{y\} {\textbackslash}in {\textbackslash}mathcal\{Y\}\} f({\textbackslash}cdot, {\textbackslash}mathbf\{y\}) efficiently. To the best our knowledge, this is the first nonasymptotic analysis for two-time-scale {GDA} in this setting, shedding light on its superior practical performance in training generative adversarial networks ({GANs}) and other real applications.},
	eventtitle = {International Conference on Machine Learning},
	pages = {6083--6093},
	booktitle = {Proceedings of the 37th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Lin, Tianyi and Jin, Chi and Jordan, Michael},
	urldate = {2022-04-20},
	date = {2020-11-21},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:C\:\\Users\\LEGION\\Zotero\\storage\\PAV4962F\\Lin et al. - 2020 - On Gradient Descent Ascent for Nonconvex-Concave M.pdf:application/pdf;Supplementary PDF:C\:\\Users\\LEGION\\Zotero\\storage\\QXJ5AMD9\\Lin et al. - 2020 - On Gradient Descent Ascent for Nonconvex-Concave M.pdf:application/pdf},
}

@inproceedings{skinner_artificial_2019,
	title = {Artificial Intelligence and Deep Learning in Video Games A Brief Review},
	doi = {10.1109/CCOMS.2019.8821783},
	abstract = {Artificial Intelligence has been used in many fields since the term was coined six decades ago. Artificial Intelligence in video games was introduced with Atari 2600's early titles such as `Computer Space' and `Pong' and has come a long way since. However, it has become expected of developers to have flawless {AI} which is as human-like as possible. Neural Networks are allowing {AI} systems to become smarter and used in ways such as {OpenAI} does with their game-playing bots. Many game-playing Neural Networks use reinforcement learning to train as it allows for more efficient training for larger games where the number of possible positions and combinations of game mechanics are extremely large. This paper provides an introductory literature review of these core fields of research as they applied within a video game context.},
	eventtitle = {2019 {IEEE} 4th International Conference on Computer and Communication Systems ({ICCCS})},
	pages = {404--408},
	booktitle = {2019 {IEEE} 4th International Conference on Computer and Communication Systems ({ICCCS})},
	author = {Skinner, Geoff and Walmsley, Toby},
	date = {2019-02},
	keywords = {Games, artificial intelligence, deep learning, Deep learning, neural networks, Neural networks, Robots, Testing, video games},
}

@inproceedings{torrado_deep_2018,
	title = {Deep Reinforcement Learning for General Video Game {AI}},
	doi = {10.1109/CIG.2018.8490422},
	abstract = {The General Video Game {AI} ({GVGAI}) competition and its associated software framework provides a way of benchmarking {AI} algorithms on a large number of games written in a domain-specific description language. While the competition has seen plenty of interest, it has so far focused on online planning, providing a forward model that allows the use of algorithms such as Monte Carlo Tree Search. In this paper, we describe how we interface {GVGAI} to the {OpenAI} Gym environment, a widely used way of connecting agents to reinforcement learning problems. Using this interface, we characterize how widely used implementations of several deep reinforcement learning algorithms fare on a number of {GVGAI} games. We further analyze the results to provide a first indication of the relative difficulty of these games relative to each other, and relative to those in the Arcade Learning Environment under similar conditions.},
	eventtitle = {2018 {IEEE} Conference on Computational Intelligence and Games ({CIG})},
	pages = {1--8},
	booktitle = {2018 {IEEE} Conference on Computational Intelligence and Games ({CIG})},
	author = {Torrado, Ruben Rodriguez and Bontrager, Philip and Togelius, Julian and Liu, Jialin and Perez-Liebana, Diego},
	date = {2018-08},
	note = {{ISSN}: 2325-4289},
	keywords = {Machine learning, Games, advantage actor critic, Benchmark testing, deep Q-learning, deep reinforcement learning, general video game {AI}, Learning (artificial intelligence), {OpenAI} Gym, Planning, video game description language},
	file = {Submitted Version:C\:\\Users\\LEGION\\Zotero\\storage\\7A6CAVK6\\Torrado et al. - 2018 - Deep Reinforcement Learning for General Video Game.pdf:application/pdf},
}

@inproceedings{lin_unsupervised_2021,
	title = {An unsupervised video game playstyle metric via state discretization},
	url = {https://proceedings.mlr.press/v161/lin21a.html},
	abstract = {On playing video games, different players usually have their own playstyles. Recently, there have been great improvements for the video game {AIs} on the playing strength. However, past researches for analyzing the behaviors of players still used heuristic rules or the behavior features with the game-environment support, thus being exhausted for the developers to define the features of discriminating various playstyles. In this paper, we propose the first metric for video game playstyles directly from the game observations and actions, without any prior specification on the playstyle in the target game. Our proposed method is built upon a novel scheme of learning discrete representations that can map game observations into latent discrete states, such that playstyles can be exhibited from these discrete states. Namely, we measure the playstyle distance based on game observations aligned to the same states. We demonstrate high playstyle accuracy of our metric in experiments on some video game platforms, including {TORCS}, {RGSK}, and seven Atari games, and for different agents including rule-based {AI} bots, learning-based {AI} bots, and human players.},
	eventtitle = {Uncertainty in Artificial Intelligence},
	pages = {215--224},
	booktitle = {Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence},
	publisher = {{PMLR}},
	author = {Lin, Chiu-Chou and Chiu, Wei-Chen and Wu, I.-Chen},
	urldate = {2022-04-20},
	date = {2021-12-01},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:C\:\\Users\\LEGION\\Zotero\\storage\\R3TG7ULW\\Lin et al. - 2021 - An unsupervised video game playstyle metric via st.pdf:application/pdf;Supplementary PDF:C\:\\Users\\LEGION\\Zotero\\storage\\V6RI6VGV\\Lin et al. - 2021 - An unsupervised video game playstyle metric via st.pdf:application/pdf},
}

@online{wilhelmstotter_jenetics_nodate,
	title = {Jenetics: Java Genetic Algorithm Library},
	url = {https://jenetics.io/},
	shorttitle = {Jenetics},
	abstract = {Jenetics is a Genetic Algorithm, Evolutionary Algorithm, Genetic Programming, and Multi-objective Optimization library, written in modern-day Java.},
	titleaddon = {jenetics.io},
	author = {Wilhelmstötter, Franz},
	urldate = {2022-04-20},
	langid = {english},
}

@article{koza_genetic_1994,
	title = {Genetic programming as a means for programming computers by natural selection},
	volume = {4},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/BF00175355},
	doi = {10.1007/BF00175355},
	abstract = {Many seemingly different problems in machine learning, artificial intelligence, and symbolic processing can be viewed as requiring the discovery of a computer program that produces some desired output for particular inputs. When viewed in this way, the process of solving these problems becomes equivalent to searching a space of possible computer programs for a highly fit individual computer program. The recently developed genetic programming paradigm described herein provides a way to search the space of possible computer programs for a highly fit individual computer program to solve (or approximately solve) a surprising variety of different problems from different fields. In genetic programming, populations of computer programs are genetically bred using the Darwinian principle of survival of the fittest and using a genetic crossover (sexual recombination) operator appropriate for genetically mating computer programs. Genetic programming is illustrated via an example of machine learning of the Boolean 11-multiplexer function and symbolic regression of the econometric exchange equation from noisy empirical data.},
	pages = {87--112},
	number = {2},
	journaltitle = {Statistics and Computing},
	shortjournal = {Stat Comput},
	author = {Koza, John R.},
	urldate = {2022-04-22},
	date = {1994-06-01},
	langid = {english},
	keywords = {Genetic programming, Boolean 11-multiplexer, Boolean 11-parity, crossover, econometric exchange equation, genetic algorithm, hierarchical automatic function definition, symbolic regression},
	file = {Submitted Version:C\:\\Users\\LEGION\\Zotero\\storage\\ZI82H9AP\\Koza - 1994 - Genetic programming as a means for programming com.pdf:application/pdf},
}

@article{kuscu_promoting_1998,
	title = {Promoting Generalisation of Learned Behaviours in Genetic Programming},
	doi = {10.1007/bfb0056891},
	abstract = {Recently, growing numbers of research concentrate on robustness of the programs evolved using Genetic Programming ({GP}). While some of the researchers report on the brittleness of the solutions evolved, some others proposed methods of promoting robustness. It is important that these methods are not ad hoc and specific for a certain experimental setup. In this research, brittleness of solutions found for the artificial ant problem is reported and a new method promoting generalisation of the solutions in {GP} is presented.},
	pages = {491--500},
	author = {Kuscu, Ibrahim},
	date = {1998-09-27},
	doi = {10.1007/bfb0056891},
	note = {{MAG} {ID}: 1598236549},
}

@article{uy_improving_2010,
	title = {Improving the generalisation ability of genetic programming with semantic similarity based crossover},
	doi = {10.1007/978-3-642-12148-7_16},
	abstract = {This paper examines the impact of semantic control on the ability of Genetic Programming ({GP}) to generalise via a semantic based crossover operator (Semantic Similarity based Crossover - {SSC}). The use of validation sets is also investigated for both standard crossover and {SSC}. All {GP} systems are tested on a number of real-valued symbolic regression problems. The experimental results show that while using validation sets barely improve generalisation ability of {GP}, by using semantics, the performance of Genetic Programming is enhanced both on training and testing data. Further recorded statistics shows that the size of the evolved solutions by using {SSC} are often smaller than ones obtained from {GP} systems that do not use semantics. This can be seen as one of the reasons for the success of {SSC} in improving the generalisation ability of {GP}.},
	pages = {184--195},
	author = {Uy, Nguyen Quang and Hien, Nguyen Thi and Hoai, Nguyen Xuan and O'Neill, Michael},
	date = {2010-04-07},
	doi = {10.1007/978-3-642-12148-7_16},
	note = {{MAG} {ID}: 1524954660},
}

@article{haeri_improving_2015,
	title = {Improving {GP} generalization: a variance-based layered learning approach},
	volume = {16},
	doi = {10.1007/s10710-014-9220-6},
	abstract = {This paper introduces a new method that improves the generalization ability of genetic programming ({GP}) for symbolic regression problems, named variance-based layered learning {GP}. In this approach, several datasets, called primitive training sets, are derived from the original training data. They are generated from less complex to more complex, for a suitable complexity measure. The last primitive dataset is still less complex than the original training set. The approach decomposes the evolution process into several hierarchical layers. The first layer of the evolution starts using the least complex (smoothest) primitive training set. In the next layers, more complex primitive sets are given to the {GP} engine. Finally, the original training data is given to the algorithm. We use the variance of the output values of a function as a measure of the functional complexity. This measure is utilized in order to generate smoother training data, and controlling the functional complexity of the solutions to reduce the overfitting. The experiments, conducted on four real-world and three artificial symbolic regression problems, demonstrate that the approach enhances the generalization ability of the {GP}, and reduces the complexity of the obtained solutions.},
	pages = {27--55},
	number = {1},
	journaltitle = {Genetic Programming and Evolvable Machines},
	author = {Haeri, Maryam Amir and Ebadzadeh, Mohammad Mehdi and Folino, Gianluigi},
	date = {2015-03-01},
	doi = {10.1007/s10710-014-9220-6},
	note = {{MAG} {ID}: 2074097796},
}

@article{raymond_multi-objective_2021,
	title = {Multi-objective genetic programming for symbolic regression with the adaptive weighted splines representation},
	doi = {10.1145/3449726.3459461},
	abstract = {Genetic Programming ({GP}) for symbolic regression often generates over-complex models, which overfit the training data and have poor generalization onto unseen data. One recent work investigated controlling model complexity by using a new {GP} representation called Adaptive Weighted Splines ({AWS}), which is a semi-structured representation that can control the model complexity explicitly. This work extends this previous work by incorporating a new parsimony pressure objective to further control the model complexity. Experimental results demonstrate that the new multi-objective {GP} method consistently obtains superior fronts and produces better generalizing models compared to single-objective {GP} with both the tree-based and {AWS} representation as well a multi-objective tree-based {GP} method with parsimony pressure.},
	pages = {165--166},
	author = {Raymond, Christian and Chen, Qi and Xue, Bing and Zhang, Mengjie},
	date = {2021-07-07},
	doi = {10.1145/3449726.3459461},
	note = {{MAG} {ID}: 3179367438},
}

@article{qi_chen_improving_2020,
	title = {Improving symbolic regression based on correlation between residuals and variables},
	doi = {10.1145/3377930.3390161},
	pages = {922--930},
	author = {{Qi Chen} and Chen, Qi and Xue, Bing and Zhang, Mengjie},
	date = {2020-06-25},
	doi = {10.1145/3377930.3390161},
	note = {{MAG} {ID}: 3039182316},
}

@article{nicolau_choosing_2021,
	title = {Choosing function sets with better generalisation performance for symbolic regression models},
	volume = {22},
	doi = {10.1007/s10710-020-09391-4},
	abstract = {Supervised learning by means of Genetic Programming ({GP}) aims at the evolutionary synthesis of a model that achieves a balance between approximating the target function on the training data and generalising on new data. The model space searched by the Evolutionary Algorithm is populated by compositions of primitive functions defined in a function set. Since the target function is unknown, the choice of function set’s constituent elements is primarily guided by the makeup of function sets traditionally used in the {GP} literature. Our work builds upon previous research of the effects of protected arithmetic operators (i.e. division, logarithm, power) on the output value of an evolved model for input data points not encountered during training. The scope is to benchmark the approximation/generalisation of models evolved using different function set choices across a range of 43 symbolic regression problems. The salient outcomes are as follows. Firstly, Koza’s protected operators of division and exponentiation have a detrimental effect on generalisation, and should therefore be avoided. This result is invariant of the use of moderately sized validation sets for model selection. Secondly, the performance of the recently introduced analytic quotient operator is comparable to that of the sinusoidal operator on average, with their combination being advantageous to both approximation and generalisation. These findings are consistent across two different system implementations, those of standard expression-tree {GP} and linear Grammatical Evolution. We highlight that this study employed very large test sets, which create confidence when benchmarking the effect of different combinations of primitive functions on model generalisation. Our aim is to encourage {GP} researchers and practitioners to use similar stringent means of assessing generalisation of evolved models where possible, and also to avoid certain primitive functions that are known to be inappropriate.},
	pages = {73--100},
	number = {1},
	journaltitle = {Genetic Programming and Evolvable Machines},
	author = {Nicolau, Miguel and Agapitos, Alexandros and Agapitos, Alexandros},
	date = {2021-03-01},
	doi = {10.1007/s10710-020-09391-4},
	note = {{MAG} {ID}: 3025201237},
}

@article{qi_chen_feature_2017,
	title = {Feature Selection to Improve Generalization of Genetic Programming for High-Dimensional Symbolic Regression},
	volume = {21},
	doi = {10.1109/tevc.2017.2683489},
	abstract = {When learning from high-dimensional data for symbolic regression ({SR}), genetic programming ({GP}) typically could not generalize well. Feature selection, as a data preprocessing method, can potentially contribute not only to improving the efficiency of learning algorithms but also to enhancing the generalization ability. However, in {GP} for high-dimensional {SR}, feature selection before learning is seldom considered. In this paper, we propose a new feature selection method based on permutation to select features for high-dimensional {SR} using {GP}. A set of experiments has been conducted to investigate the performance of the proposed method on the generalization of {GP} for high-dimensional {SR}. The regression results confirm the superior performance of the proposed method over the other examined feature selection methods. Further analysis indicates that the models evolved by the proposed method are more likely to contain only the truly relevant features and have better interpretability.},
	pages = {792--806},
	number = {5},
	journaltitle = {{IEEE} Transactions on Evolutionary Computation},
	author = {{Qi Chen} and Chen, Qi and Zhang, Mengjie and Xue, Bing},
	date = {2017-03-16},
	doi = {10.1109/tevc.2017.2683489},
	note = {{MAG} {ID}: 2595303237},
}

@article{qi_chen_improving_2016,
	title = {Improving generalisation of genetic programming for high-dimensional symbolic regression with feature selection},
	doi = {10.1109/cec.2016.7744270},
	abstract = {Feature selection is a desired process when learning from high-dimensional data. However, it is seldom considered in Genetic Programming ({GP}) for high-dimensional symbolic regression. This work aims to develop a new method, Genetic Programming with Feature Selection ({GPWFS}), to improve the generalisation ability of {GP} for symbolic regression. {GPWFS} is a two-stage method. The main task of the first stage is to select important/informative features from fittest individuals, and the second stage uses a set of selected features, which is a subset of original features, for regression. To investigate the learning/optimisation performance and generalisation capability of {GPWFS}, a set of experiments using standard {GP} as a baseline for comparison have been conducted on six real-world high-dimensional symbolic regression datasets. The experimental results show that {GPWFS} can have better performance both on the training sets and the test sets on most cases. Further analysis on the solution size, the number of distinguished features and total number of used features in the evolved models shows that using {GPWFS} can induce more compact models with better interpretability and lower computational costs than standard {GP}.},
	pages = {3793--3800},
	author = {{Qi Chen} and Chen, Qi and Xue, Bing and Niu, Ben and {Ben Niu} and Zhang, Mengjie},
	date = {2016-07-01},
	doi = {10.1109/cec.2016.7744270},
	note = {{MAG} {ID}: 2558896678},
}

@article{astarabadi_avoiding_2015,
	title = {Avoiding Overfitting in Symbolic Regression Using the First Order Derivative of {GP} Trees},
	doi = {10.1145/2739482.2764662},
	abstract = {Genetic programming ({GP}) is widely used for constructing models with applications in control, classification, regression, etc.; however, it has some shortcomings, such as generalization. This paper proposes to enhance the {GP} generalization by controlling the first order derivative of {GP} trees in the evolution process. To achieve this goal, a multi-objective {GP} is implemented. Then, the first order derivative of {GP} trees is considered as one of its objectives. The proposed method is evaluated on several benchmark problems to provide an experimental validation. The experiments demonstrate the usefulness of the proposed method with the capability of achieving compact solutions with reasonable accuracy on training data and better accuracy on test data.},
	pages = {1441--1442},
	author = {Astarabadi, Samaneh Sadat Mousavi and Ebadzadeh, Mohammad Mehdi},
	date = {2015-07-11},
	doi = {10.1145/2739482.2764662},
	note = {{MAG} {ID}: 2029700197},
}

@article{zhang_rl-gep_2021,
	title = {{RL}-{GEP}: Symbolic Regression via Gene Expression Programming and Reinforcement Learning},
	doi = {10.1109/ijcnn52387.2021.9533735},
	abstract = {Symbolic regression has become a hot topic in recent years due to the surging demand for interpretable machine learning methods. Traditionally, symbolic regression problems are mainly solved by genetic algorithms. Nonetheless, with the development of deep learning, reinforcement learning based symbolic regression methods have received attention gradually. Unfortunately, hardly any of those reinforcement learning based methods have been proven effectively to solve real world regression problems as genetic algorithm based methods. In this paper, we find a general reinforcement learning based symbolic regression method is difficult to solve real world problems since it is hard to balance between exploration and exploitation. To deal with this problem, we propose a hybrid method to use both genetic algorithm and reinforcement learning for solving symbolic regression problems. By doing so, we can combine the advantages of reinforcement learning and genetic algorithm and achieve better performance than using them alone. To validate the effectiveness of the proposed method, we apply the proposed method to ten benchmark datasets. The experimental results show that the proposed method achieves competitive performance compared with several well-known symbolic regression methods on those datasets.},
	pages = {1--8},
	author = {Zhang, Hengzhe and {Hengzhe Zhang} and Zhou, Aimin and {Aimin Zhou} and {Aimin Zhou}},
	date = {2021-07-18},
	doi = {10.1109/ijcnn52387.2021.9533735},
	note = {{MAG} {ID}: 3200734637},
}

@article{qi_chen_structural_2019,
	title = {Structural Risk Minimization-Driven Genetic Programming for Enhancing Generalization in Symbolic Regression},
	volume = {23},
	doi = {10.1109/tevc.2018.2881392},
	abstract = {Generalization ability, which reflects the prediction ability of a learned model, is an important property in genetic programming ({GP}) for symbolic regression. Structural risk minimization ({SRM}) is a framework providing a reliable estimation of the generalization performance of prediction models. Introducing the framework into {GP} has the potential to drive the evolutionary process toward models with good generalization performance. However, this is tough due to the difficulty in obtaining the Vapnik–Chervonenkis ({VC}) dimension of nonlinear models. To address this difficulty, this paper proposes an {SRM}-driven {GP} approach, which uses an  experimental  method (instead of theoretical estimation) to measure the {VC} dimension of a mixture of linear and nonlinear regression models for the first time. The  experimental  method has been conducted using uniform and nonuniform settings. The results show that our method has impressive generalization gains over standard {GP} and {GP} with the 0.632 bootstrap, and that the proposed method using the nonuniform setting has further improvement than its counterpart using the uniform setting. Further analyzes reveal that the proposed method can evolve more compact models, and that the behavioral difference between these compact models and the target models is much smaller than their counterparts evolved by the other {GP} methods.},
	pages = {703--717},
	number = {4},
	journaltitle = {{IEEE} Transactions on Evolutionary Computation},
	author = {{Qi Chen} and Chen, Qi and Zhang, Mengjie and Xue, Bing},
	date = {2019-08-01},
	doi = {10.1109/tevc.2018.2881392},
	note = {{MAG} {ID}: 2901725080},
}

@article{qi_chen_improving_2019,
	title = {Improving Generalization of Genetic Programming for Symbolic Regression With Angle-Driven Geometric Semantic Operators},
	volume = {23},
	doi = {10.1109/tevc.2018.2869621},
	abstract = {Geometric semantic genetic programming ({GP}) has recently attracted much attention. The key innovations are inducing a unimodal fitness landscape in the semantic space and providing a theoretical framework for designing geometric semantic operators. The geometric semantic operators aim to manipulate the semantics of programs by making a bounded semantic impact and generating child programs with similar or better behavior than their parents. These properties are shown to be highly related to a notable generalization improvement in {GP}. However, the potential ineffectiveness and difficulties in bounding the variations in these geometric operators still limits their positive effect on generalization. This paper attempts to further explore the geometry and search space of geometric operators to gain a greater generalization improvement in {GP} for symbolic regression. To this end, a new angle-driven selection operator and two new angle-driven geometric search operators are proposed. The angle-awareness brings new geometric properties to these geometric operators, which are expected to provide a greater leverage for approximating the target semantics in each operation, and more importantly, be resistant to overfitting. The experiments show that compared with two state-of-the-art geometric semantic operators, our angle-driven geometric operators not only drive the evolutionary process to fit the target semantics more efficiently but also improve the generalization performance. A further comparison between the evolved models shows that the new method generally produces simpler models with a much smaller size and is more likely to evolve toward the correct structure of the target models.},
	pages = {488--502},
	number = {3},
	journaltitle = {{IEEE} Transactions on Evolutionary Computation},
	author = {{Qi Chen} and Chen, Qi and Xue, Bing and Zhang, Mengjie},
	date = {2019-06-01},
	doi = {10.1109/tevc.2018.2869621},
	note = {{MAG} {ID}: 2891680306},
}

@article{arslan_multi_2019,
	title = {Multi Hive Artificial Bee Colony Programming for high dimensional symbolic regression with feature selection},
	volume = {78},
	doi = {10.1016/j.asoc.2019.03.014},
	abstract = {Abstract   Feature selection is a process that provides model extraction by specifying necessary or related features and improves generalization. The Artificial Bee Colony ({ABC}) algorithm is one of the most popular optimization algorithms inspired on swarm intelligence developed by simulating the search behavior of honey bees. Artificial Bee Colony Programming ({ABCP}) is a recently proposed high level automatic programming technique for a Symbolic Regression ({SR}) problem based on the {ABC} algorithm. In this paper, a new feature selection method based on {ABCP} is proposed, Multi Hive {ABCP} ({MHABCP}) for high-dimensional {SR} problems. The learning ability and generalization performance of the proposed {MHABCP} is investigated using synthetic and real high-dimensional {SR} datasets and is compared with basic {ABCP} and {GP} automatic programming methods. Experimental results show that {MHABCP} has better performance choosing relevant features in high dimensional {SR} problems and generalization than other methods.},
	pages = {515--527},
	journaltitle = {Applied Soft Computing},
	author = {Arslan, Sibel and Ozturk, Celal},
	date = {2019-05-01},
	doi = {10.1016/j.asoc.2019.03.014},
	note = {{MAG} {ID}: 2922470279},
}

@article{wang_multi-objective_2020,
	title = {Multi-objective feature selection based on artificial bee colony: An acceleration approach with variable sample size},
	volume = {88},
	doi = {10.1016/j.asoc.2019.106041},
	abstract = {Abstract   Due to the need to repeatedly call a classifier to evaluate individuals in the population, existing evolutionary feature selection algorithms have the disadvantage of high computational cost. In view of it, this paper studies a multi-objective feature selection framework based on sample reduction strategy and evolutionary algorithm, significantly reducing the computational cost of algorithm without affecting optimal results. In the framework, a selection strategy of representative samples, called K-means clustering based differential selection, and a ladder-like sample utilization strategy are proposed to reduce the size of samples used in the evolutionary process. Moreover, a fast multi-objective evolutionary feature selection algorithm, called {FMABC}-{FS}, is proposed by embedding an improved artificial bee colony algorithm based on the particle update model into the framework. By applying {FMABC}-{FS} to several typical {UCI} datasets, and comparing with three multi-objective feature selection algorithms, experimental results show that the proposed variable sample size strategy is more suitable to {FMABC}-{FS}, and {FMABC}-{FS} can obtain better feature subsets with much less running time than those comparison algorithms.},
	pages = {106041},
	journaltitle = {Applied Soft Computing},
	author = {Wang, Xiao-han and Zhang, Yong and Sun, Xiaoyan and Sun, Xiaoyan and Wang, Yong-li and Du, Chang-he},
	date = {2020-03-01},
	doi = {10.1016/j.asoc.2019.106041},
	note = {{MAG} {ID}: 2996901426},
}

@book{holland_adaptation_1992,
	location = {Cambridge, Mass},
	edition = {1st {MIT} Press ed},
	title = {Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence},
	isbn = {978-0-262-08213-6 978-0-262-58111-0},
	series = {Complex adaptive systems},
	shorttitle = {Adaptation in natural and artificial systems},
	pagetotal = {211},
	publisher = {{MIT} Press},
	author = {Holland, John H.},
	date = {1992},
	keywords = {Adaptation (Biology), Adaptive control systems, Mathematical models},
}

@incollection{langdon_genetic_1998,
	location = {Boston, {MA}},
	title = {Genetic Programming — Computers Using “Natural Selection” to Generate Programs},
	isbn = {978-1-4615-5731-9},
	url = {https://doi.org/10.1007/978-1-4615-5731-9_2},
	series = {The Springer International Series in Engineering and Computer Science},
	abstract = {Computers that “program themselves”; science fact or fiction? Genetic Programming uses novel optimisation techniques to “evolve” simple programs; mimicking the way humans construct programs by progressively re-writing them. Trial programs are repeatedly modified in the search for “better/fitter” solutions. The underlying basis is Genetic Algorithms ({GAs}).},
	pages = {9--42},
	booktitle = {Genetic Programming and Data Structures: Genetic Programming + Data Structures = Automatic Programming!},
	publisher = {Springer {US}},
	author = {Langdon, W. B.},
	editor = {Langdon, W. B.},
	urldate = {2022-04-23},
	date = {1998},
	langid = {english},
	doi = {10.1007/978-1-4615-5731-9_2},
	keywords = {Finite State Automaton, Fitness Function, Genetic Algorithm, Genetic Programming, Minimum Description Length},
}

@book{poli_field_2008,
	location = {[Morrisville, {NC}},
	title = {A field guide to genetic programming},
	isbn = {978-1-4092-0073-4},
	pagetotal = {233},
	publisher = {Lulu Press]},
	author = {Poli, Riccardo and Langdon, William B. and {McPhee}, Nicholas F. and Koza, John R.},
	date = {2008},
}